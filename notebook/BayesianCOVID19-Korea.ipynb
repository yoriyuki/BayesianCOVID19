{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Preprocecing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jh_dir = \"../../COVID-19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confirmed = pd.read_csv(jh_dir + \"/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Confirmed.groupby(\"Country/Region\").sum()\n",
    "df = df.drop([\"Lat\", \"Long\"], 1)\n",
    "df = df.T\n",
    "df = df.set_index(pd.to_datetime(df.index))\n",
    "confirmed = df\n",
    "confirmed = confirmed.cummax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(jh_dir + \"/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\")\n",
    "df = df.groupby(\"Country/Region\").sum()\n",
    "df = df.drop([\"Lat\", \"Long\"], 1)\n",
    "df = df.T\n",
    "df = df.set_index(pd.to_datetime(df.index))\n",
    "recovered = df.cummax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(jh_dir + \"/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\")\n",
    "df = df.groupby(\"Country/Region\").sum()\n",
    "df = df.drop([\"Lat\", \"Long\"], 1)\n",
    "df = df.T\n",
    "df = df.set_index(pd.to_datetime(df.index))\n",
    "death = df.cummax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Preparation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'Korea, South'\n",
    "epoch = pd.to_datetime('2020-02-01')\n",
    "last = pd.to_datetime('2020-04-19')\n",
    "C0 = confirmed.loc[epoch:last, country].values\n",
    "R0 = (recovered).loc[epoch:last, country].values\n",
    "D0 = death.loc[epoch:last, country].values\n",
    "P = 6000_0000\n",
    "iteration=10000\n",
    "repeat = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'T': C0.shape[0], 'T0': 0, 'P': P, 'C0': C0, 'R0': R0, 'D0':D0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_f472b1d2ccdff3099b75bd7cdafce0c4 NOW.\n"
     ]
    }
   ],
   "source": [
    "sm_const = pystan.StanModel(file=\"const.stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_4f59a82567eab0aea8cf000ab546b3ce NOW.\n"
     ]
    }
   ],
   "source": [
    "sm_every = pystan.StanModel(file=\"everyday.stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:8178 of 20000 iterations saturated the maximum tree depth of 10 (40.9 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n",
      "WARNING:pystan:Truncated summary with the 'fit.__repr__' method. For the full summary use 'print(fit)'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Warning: Shown data is truncated to 100 parameters\n",
       "For the full summary use 'print(fit)'\n",
       "\n",
       "Inference for Stan model: anon_model_f472b1d2ccdff3099b75bd7cdafce0c4.\n",
       "4 chains, each with iter=10000; warmup=5000; thin=1; \n",
       "post-warmup draws per chain=5000, total post-warmup draws=20000.\n",
       "\n",
       "              mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "init_inf    108.96    0.06   8.82  92.11 103.02 108.76 114.74 126.96  23477    1.0\n",
       "b             0.46  4.6e-3   0.57   0.03   0.12   0.26   0.57   2.11  15554    1.0\n",
       "p              0.3  2.2e-3   0.24   0.03   0.11   0.23   0.45   0.88  11191    1.0\n",
       "q              1.0  2.2e-6 3.8e-4    1.0    1.0    1.0    1.0    1.0  30641    1.0\n",
       "NI[1]        15.31    0.02   2.54  10.48  13.57  15.26  17.02   20.4  23889    1.0\n",
       "NI[2]         15.1    0.02   2.79   9.62  13.21  15.07  16.99  20.64  22502    1.0\n",
       "NI[3]        16.82    0.02   2.87  11.27  14.83  16.81  18.78  22.42  24722    1.0\n",
       "NI[4]        19.06    0.02   2.93  13.41  17.05  19.03  21.04  24.85  22993    1.0\n",
       "NI[5]        20.95    0.02   3.04  15.04  18.87  20.92   23.0  26.93  21616    1.0\n",
       "NI[6]        21.14    0.02   3.22  14.83   19.0  21.12  23.27  27.49  25053    1.0\n",
       "NI[7]        22.23    0.02    3.4  15.59  19.92  22.21  24.52  28.93  23520    1.0\n",
       "NI[8]        24.52    0.02   3.55  17.59  22.12  24.48  26.94   31.5  24916    1.0\n",
       "NI[9]         26.9    0.02   3.67   19.6  24.44  26.91  29.35  34.04  23727    1.0\n",
       "NI[10]       28.42    0.02   3.85  20.98   25.8  28.41  31.01  36.07  24427    1.0\n",
       "NI[11]       30.16    0.03    4.0  22.46   27.4  30.17  32.84  38.05  23642    1.0\n",
       "NI[12]       32.56    0.03   4.19  24.46   29.7  32.55  35.42  40.74  22596    1.0\n",
       "NI[13]       35.12    0.03   4.36  26.49  32.17  35.13  38.07  43.68  23070    1.0\n",
       "NI[14]        37.9    0.03   4.45  29.12  34.88   37.9  40.86  46.68  24703    1.0\n",
       "NI[15]       41.37    0.03    4.6  32.29  38.29  41.34  44.46  50.43  23099    1.0\n",
       "NI[16]        44.6    0.03   4.77  35.24  41.45  44.61  47.77  53.94  25459    1.0\n",
       "NI[17]       48.07    0.03   4.98  38.47  44.65  48.04   51.5  57.83  24916    1.0\n",
       "NI[18]       51.32    0.03   5.16  41.33  47.82   51.3  54.78  61.48  25222    1.0\n",
       "NI[19]       81.02    0.03   4.72  71.86   77.8  80.96  84.19  90.33  24135    1.0\n",
       "NI[20]       93.28    0.03   4.96  83.68  89.94  93.23  96.58 103.13  25360    1.0\n",
       "NI[21]      126.92    0.03   5.12 117.06 123.45 126.88 130.36 137.08  23588    1.0\n",
       "NI[22]      121.49    0.03    5.5 110.87 117.76 121.43 125.17  132.4  24750    1.0\n",
       "NI[23]      142.08    0.04   5.73 130.86 138.19 142.05 145.88 153.52  22237    1.0\n",
       "NI[24]      126.37    0.04   6.22 114.12 122.13 126.37 130.59 138.58  24463    1.0\n",
       "NI[25]      167.84    0.04   6.34 155.35 163.58 167.76 172.07 180.51  24936    1.0\n",
       "NI[26]      219.79    0.04   6.66 206.84 215.28 219.73 224.25 232.95  25191    1.0\n",
       "NI[27]      241.83    0.04   7.01  228.2 237.07 241.78 246.58 255.62  24610    1.0\n",
       "NI[28]      293.99    0.05   7.36 279.78 288.96 294.02 298.97 308.44  23709    1.0\n",
       "NI[29]      261.45    0.05   7.81 246.39 256.08 261.44 266.67 276.82  25492    1.0\n",
       "NI[30]      271.18    0.05   8.04  255.5 265.77 271.15 276.55 287.18  24549    1.0\n",
       "NI[31]      330.38    0.06   8.47 313.93 324.63 330.36  336.1 347.15  23116    1.0\n",
       "NI[32]      237.89    0.05   8.55 221.44 231.93 237.81  243.7 254.68  25255    1.0\n",
       "NI[33]      250.08    0.06   8.78 233.07 244.06 250.04 256.02  267.4  25013    1.0\n",
       "NI[34]      263.93    0.06    8.8 246.83 257.95 263.77 269.82 281.56  24984    1.0\n",
       "NI[35]       249.1    0.06   9.02 231.53 242.94 249.11 255.13 266.99  24560    1.0\n",
       "NI[36]      187.69    0.06    8.9 170.54 181.69 187.61 193.63 205.55  23801    1.0\n",
       "NI[37]      137.42    0.05   8.62 120.87 131.55 137.31 143.17 154.65  26486    1.0\n",
       "NI[38]       47.29    0.04    7.0  34.23  42.41  47.05  51.88  61.73  26745    1.0\n",
       "NI[39]      174.95    0.06   8.83 157.93 169.04 174.86 180.79 192.61  25034    1.0\n",
       "NI[40]      108.87    0.05   8.37   92.9 103.09 108.65 114.38 125.69  23827    1.0\n",
       "NI[41]      106.55    0.05   8.32  90.63 100.91 106.43 112.09 123.07  25543    1.0\n",
       "NI[42]      104.96    0.05   8.29  89.03  99.25 104.84 110.44  121.4  26751    1.0\n",
       "NI[43]       83.66    0.05   7.96   68.8  78.17  83.48  88.89  99.71  26353    1.0\n",
       "NI[44]       82.49    0.05   7.93  67.51  77.07   82.3  87.71   98.7  25709    1.0\n",
       "NI[45]       90.12    0.05   8.05  74.84  84.62  90.04  95.42 106.25  26125    1.0\n",
       "NI[46]       96.98    0.05    8.0  81.71  91.56  96.86 102.23  113.2  26853    1.0\n",
       "NI[47]      133.26    0.05    8.5 116.75 127.56 133.15 138.85  150.3  27527    1.0\n",
       "NI[48]       93.45    0.05   8.19  77.52  87.93  93.38  98.93 109.52  25419    1.0\n",
       "NI[49]      131.27    0.05   8.53 114.74 125.46 131.23 136.88 148.43  25745    1.0\n",
       "NI[50]      139.95    0.05   8.75 123.25  134.0 139.79 145.86  157.4  25853    1.0\n",
       "NI[51]        2.08    0.01   2.03   0.06   0.62   1.46    2.9   7.46  28859    1.0\n",
       "NI[52]       86.57    0.05    8.1  71.21  81.03  86.38  91.92 102.73  24234    1.0\n",
       "NI[53]      103.92    0.05   8.32  88.12  98.22 103.73 109.51 120.58  24888    1.0\n",
       "NI[54]      106.99    0.05   8.34  91.15 101.31  106.9  112.5 123.61  25927    1.0\n",
       "NI[55]       98.92    0.05   8.38  82.77  93.19  98.78 104.52 115.86  23943    1.0\n",
       "NI[56]      133.24    0.05   8.67 116.71  127.3 133.11 139.07 150.75  27525    1.0\n",
       "NI[57]      109.49    0.05   8.38  93.54 103.67 109.42  115.1 126.43  28655    1.0\n",
       "NI[58]       91.32    0.05   8.27   75.6  85.66   91.2  96.86 107.97  26685    1.0\n",
       "NI[59]      123.13    0.05   8.69 106.34 117.22 123.05 128.91 140.42  26958    1.0\n",
       "NI[60]      108.73    0.05   8.73  92.03 102.73 108.62 114.56 126.09  25712    1.0\n",
       "NI[61]      101.29    0.05   8.54  84.87  95.53 101.08  106.9 118.69  27514    1.0\n",
       "NI[62]       99.89    0.05   8.43  83.85   94.1  99.68 105.42 116.98  25923    1.0\n",
       "NI[63]      106.26    0.05   8.61  89.66 100.39 106.11 112.06 123.44  26196    1.0\n",
       "NI[64]       97.84    0.05   8.69   81.3  91.85  97.62 103.69 115.42  25279    1.0\n",
       "NI[65]       70.26    0.05   8.26  54.55  64.61  70.11  75.65  87.21  25353    1.0\n",
       "NI[66]       71.24    0.05   8.24  55.61  65.56  71.05   76.7   87.9  25810    1.0\n",
       "NI[67]       77.71    0.05   8.51  61.46  71.85  77.48   83.4  94.89  28210    1.0\n",
       "NI[68]       65.23    0.05    8.3  49.41  59.51   65.0  70.67  82.06  28416    1.0\n",
       "NI[69]       52.88    0.05   8.12  37.59  47.22  52.69  58.28  69.07  24534    1.0\n",
       "NI[70]       57.59    0.05   8.22  42.21  51.97  57.37  62.99  74.19  27310    1.0\n",
       "NI[71]       61.28    0.05   8.37  45.51  55.53   61.1  66.77  78.41  27920    1.0\n",
       "NI[72]       54.08    0.05   8.29  38.61  48.29  53.82  59.58  71.13  25267    1.0\n",
       "NI[73]        58.0    0.05   8.27  42.47  52.35  57.75  63.43  74.69  25700    1.0\n",
       "NI[74]       59.54    0.05   8.55  43.71  53.67  59.27  65.13  77.26  27978    1.0\n",
       "NI[75]       54.77    0.05    8.6  38.82  48.83  54.45  60.39  72.11  28256    1.0\n",
       "NI[76]       56.49    0.05   8.84  39.93  50.37   56.2  62.31  74.75  26073    1.0\n",
       "NI[77]        52.6    0.05   8.78  36.33  46.49  52.25  58.41  70.54  26604    1.0\n",
       "NI[78]       37.11    0.06    8.9  21.07  30.77  36.69  42.99  55.59  26013    1.0\n",
       "a             0.04  2.6e-6 4.0e-4   0.04   0.04   0.04   0.04   0.04  23042    1.0\n",
       "d           1.1e-3  4.5e-7 7.0e-5 9.4e-4 1.0e-3 1.1e-3 1.1e-3 1.2e-3  24375    1.0\n",
       "log_lik[1]   -8.95    0.01   2.03 -13.13  -10.3  -8.87  -7.53  -5.22  24409    1.0\n",
       "log_lik[2]  -15.09    0.02   2.79 -20.63 -16.98 -15.07  -13.2  -9.62  22501    1.0\n",
       "log_lik[3]  -14.01    0.02   2.69  -19.3 -15.84 -13.98 -12.13  -8.84  24904    1.0\n",
       "log_lik[4]  -12.04    0.02   2.46 -16.99 -13.69 -11.98 -10.32  -7.41  23455    1.0\n",
       "log_lik[5]   -12.0    0.02   2.45 -16.92 -13.63 -11.93 -10.29  -7.37  22005    1.0\n",
       "log_lik[6]  -18.09    0.02   3.06 -24.17 -20.12 -18.06 -16.05 -12.12  25213    1.0\n",
       "log_lik[7]  -22.22    0.02    3.4 -28.92  -24.5  -22.2 -19.91 -15.58  23523    1.0\n",
       "log_lik[8]  -21.33    0.02    3.4 -28.04 -23.63 -21.28 -19.02 -14.72  25007    1.0\n",
       "log_lik[9]  -21.01    0.02   3.39 -27.67 -23.28 -21.01 -18.74 -14.34  23946    1.0\n",
       "log_lik[10] -25.07    0.02   3.71 -32.48 -27.56 -25.05 -22.55 -17.93  24480    1.0\n",
       "log_lik[11] -30.15    0.03    4.0 -38.03 -32.83 -30.16 -27.39 -22.45  23647    1.0\n",
       "log_lik[12] -32.55    0.03   4.19 -40.73  -35.4 -32.54 -29.69 -24.44  22597    1.0\n",
       "log_lik[13] -35.11    0.03   4.36 -43.66 -38.06 -35.12 -32.16 -26.48  23076    1.0\n",
       "log_lik[14] -37.88    0.03   4.45 -46.66 -40.85 -37.89 -34.87 -29.11  24700    1.0\n",
       "log_lik[15] -37.64    0.03   4.49  -46.5 -40.65  -37.6 -34.63 -28.81  23127    1.0\n",
       "lp__         7.7e4    0.07   6.54  7.7e4  7.7e4  7.7e4  7.7e4  7.7e4   9716    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Sun Apr 26 09:19:41 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model and generate samples\n",
    "fit_const = sm_const.sampling(data=data, iter=iteration, init='random')\n",
    "fit_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:10963 of 20000 iterations saturated the maximum tree depth of 10 (54.8 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n",
      "WARNING:pystan:Truncated summary with the 'fit.__repr__' method. For the full summary use 'print(fit)'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Warning: Shown data is truncated to 100 parameters\n",
       "For the full summary use 'print(fit)'\n",
       "\n",
       "Inference for Stan model: anon_model_4f59a82567eab0aea8cf000ab546b3ce.\n",
       "4 chains, each with iter=10000; warmup=5000; thin=1; \n",
       "post-warmup draws per chain=5000, total post-warmup draws=20000.\n",
       "\n",
       "           mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "init_inf   8.56    0.02   1.85   5.05   7.42   8.84   9.19   12.8  10647    1.0\n",
       "b[1]       4.11    0.84    2.2    1.5    2.2   3.58   5.44   9.38      7   1.18\n",
       "b[2]       6.21    1.54   3.64   2.16   2.67   5.57   8.48  14.72      6   1.24\n",
       "b[3]       9.12    1.87   4.65   3.71   4.81   8.19  12.04  20.09      6   1.21\n",
       "b[4]       11.1    3.21   6.36   3.61   3.63  10.74  15.31   25.0      4   1.41\n",
       "b[5]      12.52    3.82   7.41   3.58   3.61  12.24  17.38  28.48      4   1.44\n",
       "b[6]      14.26    2.15   6.65   5.88   9.06  12.37  18.07  30.56     10   1.14\n",
       "b[7]      14.36    2.77   7.56   5.53   7.76  12.57  18.82  32.86      7   1.18\n",
       "b[8]      14.37    4.37   9.32   4.04   4.07  13.32  20.24  35.75      5   1.34\n",
       "b[9]      14.91     5.5  10.87   1.93   1.95  14.31  21.92  38.84      4   1.43\n",
       "b[10]     15.75    6.05  11.92   1.42   1.43   15.1  23.44  42.15      4   1.44\n",
       "b[11]      16.9     6.9  13.38   0.56   0.56  16.36  25.61  46.06      4   1.46\n",
       "b[12]     19.22    7.44  14.54   1.55   1.57  18.58  28.73  50.89      4   1.45\n",
       "b[13]     22.19    8.37  16.11    2.3   2.31  21.71  33.12  56.39      4   1.48\n",
       "b[14]     25.95    9.41  17.76   3.54   3.59  26.06  37.97  62.94      4   1.52\n",
       "b[15]     30.68   10.25  19.09   6.25    6.3  31.06  43.54  69.99      3   1.54\n",
       "b[16]      35.4   11.46  20.67   8.08   8.14  36.58  49.54  76.71      3   1.61\n",
       "b[17]      39.3   13.72  23.43   6.54   6.56  42.05  55.51  83.55      3   1.77\n",
       "b[18]     43.92    14.7  24.77   8.78   10.9  47.14  61.13  90.05      3   1.82\n",
       "b[19]     48.18   14.83  25.09  12.73  14.49  51.45   65.8  94.02      3   1.81\n",
       "b[20]     51.52   15.16  25.63  15.27  15.37  55.02  69.58  98.76      3   1.81\n",
       "b[21]     54.63    12.7  22.84  24.29   24.5  56.41  70.55  99.71      3   1.62\n",
       "b[22]     44.88   12.46  22.13  15.13  15.21  46.61  60.39  88.41      3   1.65\n",
       "b[23]     38.34   11.59  20.52  10.68  10.73  39.83  52.54  78.47      3   1.66\n",
       "b[24]     33.05   11.59   19.9   5.36   7.11  35.14  46.93  70.93      3   1.76\n",
       "b[25]     30.91    9.73   17.2   7.67    7.7   32.3  42.81  64.21      3   1.67\n",
       "b[26]     30.23    7.59  14.21   12.1  12.17  30.47  39.88  59.73      4   1.53\n",
       "b[27]     28.64    6.38  12.57  13.38  13.48  28.33  37.18  55.36      4   1.45\n",
       "b[28]     25.66     7.7  13.42   7.23   7.55  27.05  34.83  51.62      3   1.72\n",
       "b[29]      20.6    6.74   11.9   4.52   5.19  21.52  28.76   43.8      3   1.67\n",
       "b[30]     17.59    5.74  10.17   3.91   4.27  18.34  24.62  37.48      3   1.66\n",
       "b[31]     16.37    4.51   8.14   5.58   5.62  16.79  21.94  32.99      3   1.62\n",
       "b[32]      12.5    3.11   6.38   5.12   5.14  12.04  16.68   26.6      4   1.39\n",
       "b[33]      9.76    2.87   5.53   2.96   2.98   9.58  13.34  21.66      4   1.47\n",
       "b[34]      8.15    2.78   4.91   1.53   2.12   8.46  11.32  18.07      3   1.66\n",
       "b[35]      6.97    1.98   3.73   2.28    2.3   6.97   9.33  15.13      4   1.51\n",
       "b[36]      5.01     1.7   3.29   0.98   1.15    4.9    7.0  12.36      4   1.46\n",
       "b[37]      4.04    1.13   2.65   1.37   1.38   3.53   5.51  10.64      5   1.26\n",
       "b[38]       3.2    1.07   2.39   0.69    0.7   2.85   4.65   8.78      5   1.29\n",
       "b[39]      3.29    1.09    2.0   0.71    0.9   3.35   4.51   7.52      3   1.56\n",
       "b[40]      2.57    0.81   1.73   0.68   0.68   2.34   3.54   6.67      5   1.33\n",
       "b[41]      2.22    0.77   1.57   0.43   0.46   2.06   3.09   5.94      4   1.37\n",
       "b[42]      2.04    0.69   1.42   0.42   0.46   1.91   2.81   5.43      4   1.37\n",
       "b[43]      1.75    0.66   1.39   0.21   0.21   1.57   2.49   5.14      4   1.34\n",
       "b[44]      1.75    0.61   1.34   0.33   0.33   1.53   2.42   5.12      5   1.29\n",
       "b[45]      1.85    0.67   1.43   0.29    0.3   1.66   2.57   5.32      5   1.33\n",
       "b[46]      2.09    0.76   1.56    0.3   0.36   1.91   2.95   5.79      4   1.37\n",
       "b[47]      2.52    0.89   1.67   0.44   0.57    2.5   3.51   6.24      4   1.49\n",
       "b[48]      2.33    0.88   1.78   0.29   0.36   2.14   3.39   6.49      4   1.38\n",
       "b[49]      2.76    0.86   1.72   0.74   0.75   2.63   3.78   6.64      4    1.4\n",
       "b[50]      2.91     0.9   1.78   0.78   0.79    2.8   3.97   6.89      4   1.42\n",
       "b[51]      1.61    0.61   1.51   0.17   0.17   1.27   2.42   5.35      6   1.22\n",
       "b[52]      1.86     0.1    1.1   0.71   1.31   1.44    2.1   4.96    113   1.03\n",
       "b[53]       2.1    0.56   1.27   0.78   0.79   1.89   2.77   5.25      5   1.28\n",
       "b[54]      2.13     0.8   1.55   0.25   0.34   2.04   3.01   5.69      4   1.45\n",
       "b[55]      2.29    0.77   1.61   0.49   0.49   2.08   3.21    6.1      4   1.34\n",
       "b[56]      2.61    0.89   1.66   0.52   0.61   2.59   3.61   6.26      3    1.5\n",
       "b[57]       2.4    0.77   1.59   0.62   0.62   2.22   3.31   6.11      4   1.35\n",
       "b[58]      2.22    0.78   1.64    0.4    0.4   2.01   3.16   6.01      4   1.34\n",
       "b[59]      2.42    0.84   1.61   0.46   0.53   2.36   3.36   6.02      4   1.45\n",
       "b[60]      2.44    0.57   1.39   1.12   1.13   2.14   3.19    5.9      6   1.22\n",
       "b[61]      2.24    0.61   1.41   0.82   0.82   1.99   2.99   5.78      5   1.26\n",
       "b[62]      2.15    0.62   1.38   0.71   0.71   1.91    2.9   5.49      5   1.29\n",
       "b[63]      2.06     0.7    1.4   0.42   0.44   1.94   2.87   5.33      4    1.4\n",
       "b[64]      1.84    0.64   1.29   0.34   0.37   1.74   2.56    4.9      4   1.39\n",
       "b[65]      1.52    0.52    1.2    0.3    0.3    1.3   2.13   4.47      5   1.27\n",
       "b[66]       1.4    0.51   1.12   0.21   0.22   1.22   1.97   4.13      5    1.3\n",
       "b[67]      1.49    0.33   0.93   0.64   0.72   1.22   1.92    3.9      8   1.16\n",
       "b[68]      1.32    0.26   0.85   0.49   0.69   1.01   1.67   3.61     11   1.12\n",
       "b[69]      1.05    0.36    0.9   0.21   0.21   0.84   1.45   3.39      6   1.21\n",
       "b[70]      1.08    0.32   0.85   0.34   0.34   0.85   1.45   3.28      7   1.18\n",
       "b[71]      1.06    0.36   0.86   0.22   0.22   0.88   1.46   3.26      6   1.24\n",
       "b[72]      1.09    0.22   0.78   0.36   0.56    0.8   1.37    3.2     13    1.1\n",
       "b[73]      1.08    0.25   0.78   0.38   0.49   0.82    1.4   3.16     10   1.13\n",
       "b[74]       1.0    0.35   0.83   0.19   0.19   0.82   1.38   3.17      6   1.24\n",
       "b[75]      0.93    0.33    0.8   0.16   0.17   0.74   1.28    3.0      6   1.22\n",
       "b[76]      1.31    0.19   0.74   0.32   0.72   1.23   1.77   2.98     15   1.08\n",
       "b[77]      1.23    0.15   0.83   0.26   0.61   1.11   1.65   3.25     29   1.05\n",
       "b[78]      0.77    0.31   1.19   0.03   0.03   0.36   0.94   4.12     15   1.08\n",
       "q[1]        0.9    0.01   0.08   0.66   0.87   0.92   0.95    1.0     69   1.02\n",
       "q[2]       0.59    0.13   0.29   0.06   0.32   0.64   0.87   0.97      5   1.24\n",
       "q[3]       0.59    0.02   0.23   0.12   0.48   0.52   0.78   0.99    126   1.01\n",
       "q[4]       0.65    0.13   0.24   0.32   0.35   0.69   0.88   0.99      4   1.47\n",
       "q[5]       0.78  8.3e-4   0.15   0.39   0.72   0.78   0.89   0.99  34330    1.0\n",
       "q[6]       0.47    0.09   0.25   0.12   0.26    0.4   0.68   0.97      7   1.16\n",
       "q[7]       0.32    0.08   0.27   0.03   0.14    0.2   0.48   0.95     11    1.1\n",
       "q[8]       0.47    0.08   0.27   0.08   0.29   0.36    0.7   0.98     11    1.1\n",
       "q[9]       0.59  8.7e-3   0.22   0.16   0.47   0.54   0.75   0.98    636   1.01\n",
       "q[10]       0.5    0.07   0.24   0.07   0.28   0.55   0.66   0.95     13   1.09\n",
       "q[11]      0.33     0.1   0.24   0.01   0.11   0.28   0.56   0.86      6   1.21\n",
       "q[12]      0.32    0.15   0.28 7.7e-3   0.07    0.2   0.67   0.82      3   1.54\n",
       "q[13]      0.16  2.0e-3   0.15 5.2e-3   0.05   0.15   0.18   0.62   5640    1.0\n",
       "q[14]      0.15    0.05   0.14 3.4e-3   0.04   0.11   0.26   0.48      9   1.13\n",
       "q[15]      0.14  1.5e-3   0.11   0.01   0.07   0.14   0.16   0.44   5400   1.01\n",
       "q[16]      0.09  5.8e-4   0.06   0.01   0.05   0.08   0.09   0.25  11695    1.0\n",
       "q[17]      0.06    0.01   0.04 6.8e-3   0.03   0.06   0.09   0.15     10   1.12\n",
       "q[18]      0.02    0.01   0.02 4.3e-4 5.5e-3   0.02   0.05   0.05      4   1.47\n",
       "q[19]      0.89    0.04   0.13   0.55   0.82   0.96   0.98    1.0     13    1.1\n",
       "q[20]      0.78    0.08   0.15   0.51   0.67   0.78   0.96   0.96      4   1.45\n",
       "lp__      8.1e4  1927.9 2726.6  7.6e4  7.9e4  8.2e4  8.2e4  8.2e4      2  232.6\n",
       "\n",
       "Samples were drawn using NUTS at Sun Apr 26 09:35:05 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model and generate samples\n",
    "inits = 'random'\n",
    "fit_every = sm_every.sampling(data=data, iter=iteration, init=inits, control={'adapt_delta':0.99999})\n",
    "fit_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_4f59a82567eab0aea8cf000ab546b3ce.\n",
      "4 chains, each with iter=10000; warmup=5000; thin=1; \n",
      "post-warmup draws per chain=5000, total post-warmup draws=20000.\n",
      "\n",
      "              mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "init_inf      8.56    0.02   1.85   5.05   7.42   8.84   9.19   12.8  10647    1.0\n",
      "b[1]          4.11    0.84    2.2    1.5    2.2   3.58   5.44   9.38      7   1.18\n",
      "b[2]          6.21    1.54   3.64   2.16   2.67   5.57   8.48  14.72      6   1.24\n",
      "b[3]          9.12    1.87   4.65   3.71   4.81   8.19  12.04  20.09      6   1.21\n",
      "b[4]          11.1    3.21   6.36   3.61   3.63  10.74  15.31   25.0      4   1.41\n",
      "b[5]         12.52    3.82   7.41   3.58   3.61  12.24  17.38  28.48      4   1.44\n",
      "b[6]         14.26    2.15   6.65   5.88   9.06  12.37  18.07  30.56     10   1.14\n",
      "b[7]         14.36    2.77   7.56   5.53   7.76  12.57  18.82  32.86      7   1.18\n",
      "b[8]         14.37    4.37   9.32   4.04   4.07  13.32  20.24  35.75      5   1.34\n",
      "b[9]         14.91     5.5  10.87   1.93   1.95  14.31  21.92  38.84      4   1.43\n",
      "b[10]        15.75    6.05  11.92   1.42   1.43   15.1  23.44  42.15      4   1.44\n",
      "b[11]         16.9     6.9  13.38   0.56   0.56  16.36  25.61  46.06      4   1.46\n",
      "b[12]        19.22    7.44  14.54   1.55   1.57  18.58  28.73  50.89      4   1.45\n",
      "b[13]        22.19    8.37  16.11    2.3   2.31  21.71  33.12  56.39      4   1.48\n",
      "b[14]        25.95    9.41  17.76   3.54   3.59  26.06  37.97  62.94      4   1.52\n",
      "b[15]        30.68   10.25  19.09   6.25    6.3  31.06  43.54  69.99      3   1.54\n",
      "b[16]         35.4   11.46  20.67   8.08   8.14  36.58  49.54  76.71      3   1.61\n",
      "b[17]         39.3   13.72  23.43   6.54   6.56  42.05  55.51  83.55      3   1.77\n",
      "b[18]        43.92    14.7  24.77   8.78   10.9  47.14  61.13  90.05      3   1.82\n",
      "b[19]        48.18   14.83  25.09  12.73  14.49  51.45   65.8  94.02      3   1.81\n",
      "b[20]        51.52   15.16  25.63  15.27  15.37  55.02  69.58  98.76      3   1.81\n",
      "b[21]        54.63    12.7  22.84  24.29   24.5  56.41  70.55  99.71      3   1.62\n",
      "b[22]        44.88   12.46  22.13  15.13  15.21  46.61  60.39  88.41      3   1.65\n",
      "b[23]        38.34   11.59  20.52  10.68  10.73  39.83  52.54  78.47      3   1.66\n",
      "b[24]        33.05   11.59   19.9   5.36   7.11  35.14  46.93  70.93      3   1.76\n",
      "b[25]        30.91    9.73   17.2   7.67    7.7   32.3  42.81  64.21      3   1.67\n",
      "b[26]        30.23    7.59  14.21   12.1  12.17  30.47  39.88  59.73      4   1.53\n",
      "b[27]        28.64    6.38  12.57  13.38  13.48  28.33  37.18  55.36      4   1.45\n",
      "b[28]        25.66     7.7  13.42   7.23   7.55  27.05  34.83  51.62      3   1.72\n",
      "b[29]         20.6    6.74   11.9   4.52   5.19  21.52  28.76   43.8      3   1.67\n",
      "b[30]        17.59    5.74  10.17   3.91   4.27  18.34  24.62  37.48      3   1.66\n",
      "b[31]        16.37    4.51   8.14   5.58   5.62  16.79  21.94  32.99      3   1.62\n",
      "b[32]         12.5    3.11   6.38   5.12   5.14  12.04  16.68   26.6      4   1.39\n",
      "b[33]         9.76    2.87   5.53   2.96   2.98   9.58  13.34  21.66      4   1.47\n",
      "b[34]         8.15    2.78   4.91   1.53   2.12   8.46  11.32  18.07      3   1.66\n",
      "b[35]         6.97    1.98   3.73   2.28    2.3   6.97   9.33  15.13      4   1.51\n",
      "b[36]         5.01     1.7   3.29   0.98   1.15    4.9    7.0  12.36      4   1.46\n",
      "b[37]         4.04    1.13   2.65   1.37   1.38   3.53   5.51  10.64      5   1.26\n",
      "b[38]          3.2    1.07   2.39   0.69    0.7   2.85   4.65   8.78      5   1.29\n",
      "b[39]         3.29    1.09    2.0   0.71    0.9   3.35   4.51   7.52      3   1.56\n",
      "b[40]         2.57    0.81   1.73   0.68   0.68   2.34   3.54   6.67      5   1.33\n",
      "b[41]         2.22    0.77   1.57   0.43   0.46   2.06   3.09   5.94      4   1.37\n",
      "b[42]         2.04    0.69   1.42   0.42   0.46   1.91   2.81   5.43      4   1.37\n",
      "b[43]         1.75    0.66   1.39   0.21   0.21   1.57   2.49   5.14      4   1.34\n",
      "b[44]         1.75    0.61   1.34   0.33   0.33   1.53   2.42   5.12      5   1.29\n",
      "b[45]         1.85    0.67   1.43   0.29    0.3   1.66   2.57   5.32      5   1.33\n",
      "b[46]         2.09    0.76   1.56    0.3   0.36   1.91   2.95   5.79      4   1.37\n",
      "b[47]         2.52    0.89   1.67   0.44   0.57    2.5   3.51   6.24      4   1.49\n",
      "b[48]         2.33    0.88   1.78   0.29   0.36   2.14   3.39   6.49      4   1.38\n",
      "b[49]         2.76    0.86   1.72   0.74   0.75   2.63   3.78   6.64      4    1.4\n",
      "b[50]         2.91     0.9   1.78   0.78   0.79    2.8   3.97   6.89      4   1.42\n",
      "b[51]         1.61    0.61   1.51   0.17   0.17   1.27   2.42   5.35      6   1.22\n",
      "b[52]         1.86     0.1    1.1   0.71   1.31   1.44    2.1   4.96    113   1.03\n",
      "b[53]          2.1    0.56   1.27   0.78   0.79   1.89   2.77   5.25      5   1.28\n",
      "b[54]         2.13     0.8   1.55   0.25   0.34   2.04   3.01   5.69      4   1.45\n",
      "b[55]         2.29    0.77   1.61   0.49   0.49   2.08   3.21    6.1      4   1.34\n",
      "b[56]         2.61    0.89   1.66   0.52   0.61   2.59   3.61   6.26      3    1.5\n",
      "b[57]          2.4    0.77   1.59   0.62   0.62   2.22   3.31   6.11      4   1.35\n",
      "b[58]         2.22    0.78   1.64    0.4    0.4   2.01   3.16   6.01      4   1.34\n",
      "b[59]         2.42    0.84   1.61   0.46   0.53   2.36   3.36   6.02      4   1.45\n",
      "b[60]         2.44    0.57   1.39   1.12   1.13   2.14   3.19    5.9      6   1.22\n",
      "b[61]         2.24    0.61   1.41   0.82   0.82   1.99   2.99   5.78      5   1.26\n",
      "b[62]         2.15    0.62   1.38   0.71   0.71   1.91    2.9   5.49      5   1.29\n",
      "b[63]         2.06     0.7    1.4   0.42   0.44   1.94   2.87   5.33      4    1.4\n",
      "b[64]         1.84    0.64   1.29   0.34   0.37   1.74   2.56    4.9      4   1.39\n",
      "b[65]         1.52    0.52    1.2    0.3    0.3    1.3   2.13   4.47      5   1.27\n",
      "b[66]          1.4    0.51   1.12   0.21   0.22   1.22   1.97   4.13      5    1.3\n",
      "b[67]         1.49    0.33   0.93   0.64   0.72   1.22   1.92    3.9      8   1.16\n",
      "b[68]         1.32    0.26   0.85   0.49   0.69   1.01   1.67   3.61     11   1.12\n",
      "b[69]         1.05    0.36    0.9   0.21   0.21   0.84   1.45   3.39      6   1.21\n",
      "b[70]         1.08    0.32   0.85   0.34   0.34   0.85   1.45   3.28      7   1.18\n",
      "b[71]         1.06    0.36   0.86   0.22   0.22   0.88   1.46   3.26      6   1.24\n",
      "b[72]         1.09    0.22   0.78   0.36   0.56    0.8   1.37    3.2     13    1.1\n",
      "b[73]         1.08    0.25   0.78   0.38   0.49   0.82    1.4   3.16     10   1.13\n",
      "b[74]          1.0    0.35   0.83   0.19   0.19   0.82   1.38   3.17      6   1.24\n",
      "b[75]         0.93    0.33    0.8   0.16   0.17   0.74   1.28    3.0      6   1.22\n",
      "b[76]         1.31    0.19   0.74   0.32   0.72   1.23   1.77   2.98     15   1.08\n",
      "b[77]         1.23    0.15   0.83   0.26   0.61   1.11   1.65   3.25     29   1.05\n",
      "b[78]         0.77    0.31   1.19   0.03   0.03   0.36   0.94   4.12     15   1.08\n",
      "q[1]           0.9    0.01   0.08   0.66   0.87   0.92   0.95    1.0     69   1.02\n",
      "q[2]          0.59    0.13   0.29   0.06   0.32   0.64   0.87   0.97      5   1.24\n",
      "q[3]          0.59    0.02   0.23   0.12   0.48   0.52   0.78   0.99    126   1.01\n",
      "q[4]          0.65    0.13   0.24   0.32   0.35   0.69   0.88   0.99      4   1.47\n",
      "q[5]          0.78  8.3e-4   0.15   0.39   0.72   0.78   0.89   0.99  34330    1.0\n",
      "q[6]          0.47    0.09   0.25   0.12   0.26    0.4   0.68   0.97      7   1.16\n",
      "q[7]          0.32    0.08   0.27   0.03   0.14    0.2   0.48   0.95     11    1.1\n",
      "q[8]          0.47    0.08   0.27   0.08   0.29   0.36    0.7   0.98     11    1.1\n",
      "q[9]          0.59  8.7e-3   0.22   0.16   0.47   0.54   0.75   0.98    636   1.01\n",
      "q[10]          0.5    0.07   0.24   0.07   0.28   0.55   0.66   0.95     13   1.09\n",
      "q[11]         0.33     0.1   0.24   0.01   0.11   0.28   0.56   0.86      6   1.21\n",
      "q[12]         0.32    0.15   0.28 7.7e-3   0.07    0.2   0.67   0.82      3   1.54\n",
      "q[13]         0.16  2.0e-3   0.15 5.2e-3   0.05   0.15   0.18   0.62   5640    1.0\n",
      "q[14]         0.15    0.05   0.14 3.4e-3   0.04   0.11   0.26   0.48      9   1.13\n",
      "q[15]         0.14  1.5e-3   0.11   0.01   0.07   0.14   0.16   0.44   5400   1.01\n",
      "q[16]         0.09  5.8e-4   0.06   0.01   0.05   0.08   0.09   0.25  11695    1.0\n",
      "q[17]         0.06    0.01   0.04 6.8e-3   0.03   0.06   0.09   0.15     10   1.12\n",
      "q[18]         0.02    0.01   0.02 4.3e-4 5.5e-3   0.02   0.05   0.05      4   1.47\n",
      "q[19]         0.89    0.04   0.13   0.55   0.82   0.96   0.98    1.0     13    1.1\n",
      "q[20]         0.78    0.08   0.15   0.51   0.67   0.78   0.96   0.96      4   1.45\n",
      "q[21]         0.95  2.0e-3   0.05   0.82   0.94   0.96   0.98    1.0    525   1.01\n",
      "q[22]         0.63    0.02    0.1   0.44   0.56   0.65   0.68   0.83     34   1.04\n",
      "q[23]         0.71    0.04   0.13   0.46   0.61   0.73   0.82   0.94      8   1.15\n",
      "q[24]         0.43     0.1   0.15   0.23   0.31   0.38   0.66   0.66      2   2.33\n",
      "q[25]         0.63    0.09   0.16   0.37   0.51   0.61   0.84   0.84      3   1.59\n",
      "q[26]         0.79    0.02   0.11   0.57   0.73   0.76   0.88   0.99     21   1.06\n",
      "q[27]          0.7    0.09   0.16   0.48   0.48   0.72   0.83   0.97      3    1.7\n",
      "q[28]          0.9  6.1e-3   0.07   0.72   0.87   0.89   0.95    1.0    134   1.02\n",
      "q[29]         0.68  4.6e-3    0.1   0.47   0.61    0.7   0.71   0.91    487   1.01\n",
      "q[30]         0.68  4.8e-3   0.11   0.47   0.61   0.71   0.72   0.93    522   1.01\n",
      "q[31]         0.83    0.07   0.12   0.67   0.67   0.86   0.95    1.0      3   1.63\n",
      "q[32]         0.51    0.07   0.15   0.35   0.35    0.5    0.6   0.85      4   1.34\n",
      "q[33]         0.64    0.06   0.15   0.42   0.51   0.61   0.76   0.97      7   1.17\n",
      "q[34]         0.83    0.06   0.14   0.51   0.73   0.87   0.97   0.99      6   1.23\n",
      "q[35]         0.75    0.06   0.14   0.52   0.61   0.74   0.88   0.99      5   1.24\n",
      "q[36]         0.67  1.9e-3   0.15   0.36   0.57   0.69   0.75   0.97   6336    1.0\n",
      "q[37]         0.48    0.08    0.2   0.24    0.3   0.42   0.61   0.94      7   1.19\n",
      "q[38]         0.17  8.3e-3    0.1   0.06   0.11   0.16    0.2   0.41    137   1.02\n",
      "q[39]         0.87    0.06   0.15   0.48   0.79   0.92    1.0    1.0      7   1.17\n",
      "q[40]         0.52    0.05   0.19   0.25   0.41   0.45   0.64   0.95     15   1.08\n",
      "q[41]         0.64    0.03   0.18   0.27    0.5   0.71   0.71   0.97     53   1.03\n",
      "q[42]         0.69    0.05   0.19   0.28   0.54   0.76   0.81   0.98     14   1.09\n",
      "q[43]         0.61    0.06   0.21   0.21   0.43   0.66   0.74   0.97     13   1.09\n",
      "q[44]         0.52    0.05   0.21   0.21   0.39   0.44   0.67   0.97     15   1.08\n",
      "q[45]          0.6  2.2e-3   0.19   0.24   0.47   0.61   0.71   0.97   7537    1.0\n",
      "q[46]         0.65    0.08   0.21   0.24   0.47   0.69   0.83   0.97      8   1.16\n",
      "q[47]         0.75  9.7e-3   0.16   0.38   0.66    0.8   0.85   0.99    273   1.02\n",
      "q[48]         0.57    0.08   0.21   0.21   0.38   0.58   0.76   0.94      7   1.18\n",
      "q[49]         0.65    0.05   0.18   0.34   0.54    0.6    0.8   0.98     15   1.08\n",
      "q[50]         0.71  5.4e-3   0.16   0.36   0.61   0.75    0.8   0.98    887   1.01\n",
      "q[51]         0.02  7.3e-4   0.04 9.9e-4 6.3e-3   0.02   0.03   0.09   3825    1.0\n",
      "q[52]         0.58    0.17   0.32   0.18   0.18   0.57   0.91    1.0      4   1.48\n",
      "q[53]         0.61    0.08    0.2    0.3   0.43   0.57   0.78   0.98      7   1.18\n",
      "q[54]         0.73    0.11   0.23   0.29   0.55   0.77   0.98   0.98      5   1.32\n",
      "q[55]         0.58  2.2e-3   0.18   0.24   0.45    0.6   0.67   0.96   7198    1.0\n",
      "q[56]         0.75  5.0e-3   0.16   0.38   0.66   0.79   0.85   0.99    985   1.01\n",
      "q[57]         0.61  4.4e-3   0.18   0.28   0.51   0.56   0.73   0.97   1654   1.01\n",
      "q[58]         0.54    0.01   0.19   0.21    0.4    0.6    0.6   0.95    238   1.02\n",
      "q[59]         0.77    0.08    0.2   0.34   0.62   0.82   0.95   0.98      6   1.22\n",
      "q[60]         0.54    0.12   0.24   0.25   0.25   0.52   0.74   0.98      4   1.41\n",
      "q[61]         0.55    0.08   0.21   0.26   0.37   0.49   0.72   0.97      8   1.16\n",
      "q[62]         0.55    0.08   0.21   0.26   0.36   0.49   0.72   0.97      7   1.18\n",
      "q[63]          0.7    0.04   0.19    0.3   0.56   0.78    0.8   0.98     21   1.06\n",
      "q[64]         0.73     0.1   0.22   0.28   0.54   0.76   0.96   0.98      5   1.27\n",
      "q[65]          0.5  3.0e-3    0.2   0.18   0.38   0.46   0.61   0.95   4296   1.01\n",
      "q[66]         0.57    0.02    0.2   0.19   0.41   0.64   0.66   0.97    152   1.02\n",
      "q[67]         0.52    0.13   0.26   0.23   0.23    0.5   0.74   0.98      4   1.37\n",
      "q[68]         0.48    0.11   0.25   0.19   0.22   0.42   0.68   0.97      5   1.26\n",
      "q[69]          0.5  2.4e-3   0.21   0.14   0.34    0.5   0.59   0.96   7669    1.0\n",
      "q[70]         0.44    0.12   0.27   0.16   0.16   0.39   0.65   0.97      5   1.29\n",
      "q[71]         0.55  2.9e-3   0.21   0.18   0.42    0.5   0.69   0.97   5180   1.01\n",
      "q[72]         0.42    0.11   0.26   0.15   0.17   0.36   0.61   0.96      6   1.24\n",
      "q[73]         0.44    0.12   0.27   0.16   0.16   0.38   0.65   0.97      5   1.29\n",
      "q[74]         0.61    0.08   0.24   0.16    0.4   0.67    0.8   0.97      8   1.15\n",
      "q[75]         0.59     0.1   0.25   0.14   0.36   0.62   0.82   0.96      6    1.2\n",
      "q[76]         0.41    0.15    0.3   0.06   0.06   0.38   0.66   0.97      4   1.42\n",
      "q[77]         0.39    0.15    0.3   0.04   0.04   0.35   0.64   0.97      4   1.39\n",
      "q[78]         0.54    0.19   0.36   0.04   0.18    0.5   0.98   0.98      4   1.47\n",
      "NI[1]         1.26    0.18    0.5   0.39   0.86   1.27   1.67   2.24      8   1.15\n",
      "NI[2]         0.71    0.09   0.55   0.04   0.43   0.48   0.93   2.17     37   1.04\n",
      "NI[3]         1.68    0.38   0.85   0.28   0.96   1.62   2.54   3.13      5   1.26\n",
      "NI[4]         2.53    0.35   0.95   0.84   1.76   2.57   3.32   4.31      7   1.16\n",
      "NI[5]          2.8    0.01   0.96   1.19   2.27   2.64    3.2   5.15   9051   1.01\n",
      "NI[6]         2.74    0.74   1.45   0.44   1.49   2.52   4.43   4.92      4   1.39\n",
      "NI[7]         2.63    0.93   1.75   0.12    1.1   2.27   4.77   5.03      4   1.48\n",
      "NI[8]          3.6     1.2   2.09   0.54   1.86   3.07   6.42   6.44      3   1.67\n",
      "NI[9]         3.55    0.02   1.46   1.03   2.57    3.8   3.95   7.09   6709   1.01\n",
      "NI[10]        3.15    0.67    2.0   0.77   1.59   2.54   4.23   8.16      9   1.14\n",
      "NI[11]        3.02    1.29   2.88   0.05   0.05   2.51    4.8   9.83      5   1.28\n",
      "NI[12]        4.06     1.7   3.67   0.14   0.14   3.61   6.38  12.53      5   1.31\n",
      "NI[13]        6.67    0.98   3.86   1.26   4.25   5.34   8.75  16.27     16   1.09\n",
      "NI[14]        9.32    1.89   5.35   2.35   4.88   8.06  12.54  22.16      8   1.16\n",
      "NI[15]        14.9    1.65   6.39   5.69  10.85  12.78  18.34  30.95     15   1.09\n",
      "NI[16]       22.49    2.38   8.36  11.02  16.71  19.94  27.11  42.93     12   1.11\n",
      "NI[17]       31.81    7.18  13.84   15.0  15.07  31.71  40.72  61.87      4   1.45\n",
      "NI[18]       48.91   11.57  20.17   21.6  21.75  50.77  62.17  88.84      3   1.67\n",
      "NI[19]       82.73    8.75  18.68  62.13   62.8  80.71  92.34  127.9      5   1.32\n",
      "NI[20]      127.81   18.53  31.46   83.9  85.51  131.4 148.79 188.66      3   1.75\n",
      "NI[21]      225.42    3.77  18.68 197.45 215.65 218.86 234.64 270.64     25   1.05\n",
      "NI[22]      278.45    3.97  39.69 208.81 261.74 265.72 299.33 371.31    100   1.03\n",
      "NI[23]      334.55   24.71  67.63 250.47 276.89 318.72 376.08 496.04      7   1.17\n",
      "NI[24]      376.59   71.66 125.86 207.07 209.68 387.19 460.56 625.21      3   1.65\n",
      "NI[25]      481.78   57.22  122.5 347.44 350.32 470.78 559.69 758.63      5   1.32\n",
      "NI[26]      658.22   20.51  99.85 503.64 577.24 665.82 711.33 888.97     24   1.06\n",
      "NI[27]      862.76  132.14 209.03 591.09  693.6 792.43 1173.6 1179.7      3   2.14\n",
      "NI[28]      913.36   13.18  84.87 788.42 849.17 915.54  951.1 1123.3     41   1.04\n",
      "NI[29]      871.58   40.98 146.67 654.97 774.17 827.07  957.1 1221.2     13   1.09\n",
      "NI[30]       885.5   41.92 158.85 650.79 783.41 832.29 974.65 1273.2     14   1.08\n",
      "NI[31]      1030.1   84.27 154.27 828.36 897.49 981.52 1221.6 1249.2      3   1.53\n",
      "NI[32]      954.55  177.87 290.25 521.74 722.95 876.75 1372.1 1380.4      3   1.93\n",
      "NI[33]      775.63   73.18 179.83  482.5 621.58 770.48 943.73 1100.0      6   1.21\n",
      "NI[34]      626.45   50.93 137.17  503.1 510.54 585.05 693.33 984.63      7   1.17\n",
      "NI[35]      618.93   50.54 124.35  442.3 509.11 600.33 734.85 862.13      6   1.21\n",
      "NI[36]      424.25   25.87 125.07 278.95  356.4 366.09 478.04 751.18     23   1.06\n",
      "NI[37]      396.66   56.96 144.76 173.52 271.34 388.66 527.84 669.34      6    1.2\n",
      "NI[38]      277.35    9.74 118.39   87.2 220.78 240.69 330.86 576.27    148   1.02\n",
      "NI[39]      295.29   10.29  71.53 228.18 263.06 265.57  307.3 501.15     48   1.04\n",
      "NI[40]      243.63     7.8  84.69 118.79 178.62 254.64  273.0 452.46    118   1.02\n",
      "NI[41]      192.06    16.7  78.35  110.4 149.58 155.52 221.22 403.91     22   1.06\n",
      "NI[42]      173.49   18.49  73.51 104.25 128.33  142.0 198.96  372.7     16   1.08\n",
      "NI[43]      144.47   23.67  76.88  76.54  88.86 115.77 175.37 352.84     11   1.11\n",
      "NI[44]      152.57    1.89  69.03  73.71 110.56 137.46 169.39  341.0   1336   1.01\n",
      "NI[45]       154.7   13.39  71.61  82.68 118.85 119.95 177.25 352.71     29   1.05\n",
      "NI[46]      166.94   23.45  78.75  93.26  111.3 136.12 199.88 375.56     11   1.11\n",
      "NI[47]      208.11    17.5   69.5  145.3 165.68 179.05 229.57 403.14     16   1.08\n",
      "NI[48]      177.51   36.26  93.48  92.42   94.3 152.16 226.63 412.55      7   1.19\n",
      "NI[49]      238.61    0.95   72.8 143.71 184.96 246.65 252.66 424.68   5828   1.01\n",
      "NI[50]      248.89    0.89  71.84  156.6 199.14 250.67 261.73 439.78   6588    1.0\n",
      "NI[51]       118.4   22.86  83.16  18.22  63.68  88.69 157.41  335.2     13   1.09\n",
      "NI[52]      210.62   98.18 150.34   68.0  87.83 133.99  445.7 447.37      2   2.49\n",
      "NI[53]      184.39   21.67  65.16  96.16 128.14 176.26 235.02 326.88      9   1.14\n",
      "NI[54]      157.15   29.18  73.39  89.39  89.98 137.32 190.54 347.03      6    1.2\n",
      "NI[55]      177.56    7.15  71.35  92.35 137.12 153.68 202.22 370.21     99   1.02\n",
      "NI[56]      202.67   12.15  62.78 139.94 171.31 172.75 220.72 377.95     27   1.05\n",
      "NI[57]      192.11    0.77  66.91 105.02 145.25 192.81  206.1 370.91   7591    1.0\n",
      "NI[58]      166.07   14.71  74.37  81.34 128.07  129.9  197.2 361.17     26   1.05\n",
      "NI[59]      183.16   12.56  63.86 120.53 149.62 153.21 202.64 361.94     26   1.05\n",
      "NI[60]      228.18   60.74 104.33  99.69 137.12 193.14 370.46 371.94      3   1.71\n",
      "NI[61]      195.61   34.26  78.82  88.01 125.22 180.77  274.4 345.41      5   1.25\n",
      "NI[62]      178.32   20.26  67.11  85.35 120.31 173.45 226.08 327.93     11   1.11\n",
      "NI[63]      148.23   14.08  59.92  90.74 113.05 121.55 168.39 314.35     18   1.07\n",
      "NI[64]      134.73    7.93  55.05  78.48 106.64 111.85 150.55  289.7     48   1.04\n",
      "NI[65]      109.12    4.84  55.06  47.56  78.55  91.15 125.25  261.5    130   1.02\n",
      "NI[66]       95.82   12.16  51.92  46.22  65.62  72.75 114.11 237.33     18   1.07\n",
      "NI[67]      129.77   36.53  65.72  50.03  72.44 106.78 214.46 219.42      3   1.57\n",
      "NI[68]      114.89    36.3  64.31  36.93  58.35  92.56 199.62 200.67      3   1.61\n",
      "NI[69]       69.21    4.74  41.12  26.59  46.74  54.55  79.69  184.0     75   1.03\n",
      "NI[70]       78.92    6.39  40.33  28.35  46.66  77.45   96.8 179.72     40   1.04\n",
      "NI[71]       71.72    0.42  37.29   30.1  47.65  69.54  76.01 173.24   7733    1.0\n",
      "NI[72]       85.15   24.65  49.63  23.59  41.86  70.05 141.75 166.56      4   1.38\n",
      "NI[73]       83.15   22.13  46.12  25.33  42.27  70.53 133.38 162.37      4   1.34\n",
      "NI[74]       58.44    6.28  35.62  25.26  41.39  42.09  67.52 155.96     32   1.04\n",
      "NI[75]       51.93    7.27  34.36  20.93  33.53  36.57  61.35 147.65     22   1.06\n",
      "NI[76]      162.27  131.05 187.58  20.06  34.58  58.15  479.7 483.49      2   6.13\n",
      "NI[77]      151.08   122.6 176.53  16.13  28.97  51.32 448.11 451.88      2   5.04\n",
      "NI[78]        37.2    12.4  56.63   6.43   6.47  16.19  42.28 188.45     21   1.06\n",
      "a             0.03  4.5e-5 3.1e-4   0.03   0.03   0.03   0.03   0.03     48   1.03\n",
      "d           6.8e-4  2.8e-4 4.0e-4  1e-15 3.2e-4 8.8e-4 9.4e-4 1.0e-3      2   8.23\n",
      "p             0.02  9.4e-3   0.01 5.4e-3 7.8e-310.0e-3   0.04   0.04      2   6.04\n",
      "log_lik[1]   -2.85    0.36    1.0  -5.36   -3.4  -2.56  -2.04  -1.71      8   1.15\n",
      "log_lik[2]   -0.37  2.3e-3   0.31  -1.22  -0.42   -0.4  -0.15  -0.01  18310    1.0\n",
      "log_lik[3]   -1.24    0.08   0.39   -2.4  -1.28  -1.05  -1.04   -1.0     25   1.05\n",
      "log_lik[4]   -2.34    0.03   0.74  -4.32  -2.51  -2.39  -1.77   -1.5    489   1.01\n",
      "log_lik[5]   -2.55    0.05   0.83  -4.82  -2.78  -2.35  -2.04  -1.64    282   1.01\n",
      "log_lik[6]    -1.2    0.08   0.33  -2.18  -1.25  -1.05  -1.01   -1.0     18   1.07\n",
      "log_lik[7]   -0.63  3.6e-3   0.53  -2.08  -0.68  -0.66  -0.24  -0.02  21277    1.0\n",
      "log_lik[8]   -1.29  4.0e-3   0.37  -2.36   -1.3  -1.23  -1.06   -1.0   8679    1.0\n",
      "log_lik[9]   -1.56     0.1   0.43   -2.8  -1.62  -1.37  -1.31  -1.31     18   1.07\n",
      "log_lik[10]  -1.24     0.1   0.41  -2.44   -1.3  -1.06   -1.0   -1.0     18   1.07\n",
      "log_lik[11]  -0.59    0.25   0.73  -2.58  -0.86  -0.34  -0.03  -0.03      9   1.13\n",
      "log_lik[12]  -0.61    0.23   0.74  -2.66  -0.85  -0.33  -0.09  -0.03     10   1.11\n",
      "log_lik[13]  -0.81  4.4e-3   0.71  -2.76   -0.9  -0.77  -0.35  -0.04  25547    1.0\n",
      "log_lik[14]  -0.99    0.09   0.79  -3.06  -1.25  -0.99  -0.39  -0.04     76   1.02\n",
      "log_lik[15]  -1.42    0.09   0.64  -3.27  -1.46  -1.18  -1.09   -1.0     55   1.03\n",
      "log_lik[16]  -1.39    0.13   0.64  -3.24  -1.46  -1.09  -1.06   -1.0     22   1.05\n",
      "log_lik[17]   -1.4    0.14   0.65  -3.29  -1.49  -1.09  -1.07   -1.0     22   1.05\n",
      "log_lik[18]  -0.88  8.0e-3   0.76   -2.9  -1.02  -0.91  -0.31  -0.02   8927   1.01\n",
      "log_lik[19]   -3.7     0.2   0.65  -5.22  -4.15  -3.51  -3.15  -3.07     10   1.12\n",
      "log_lik[20]  -4.12    0.53   0.93  -5.44  -5.32  -3.68  -3.31  -3.22      3   1.64\n",
      "log_lik[21]  -4.61  9.7e-3   0.99  -7.35  -4.78  -4.62  -3.86  -3.64  10443    1.0\n",
      "log_lik[22]  -3.93    0.04   0.63  -5.72  -3.96  -3.73  -3.58  -3.49    245   1.02\n",
      "log_lik[23]  -4.03    0.13   0.63  -5.87  -4.11  -3.74  -3.69  -3.64     23   1.06\n",
      "log_lik[24]  -3.81    0.09   0.63  -5.64  -3.88  -3.57   -3.5  -3.41     46   1.04\n",
      "log_lik[25]  -4.17    0.08   0.63  -6.03  -4.21  -3.94  -3.84  -3.74     63   1.03\n",
      "log_lik[26]  -4.43    0.11   0.63  -6.28   -4.5  -4.16  -4.13  -4.03     34   1.04\n",
      "log_lik[27]  -4.48    0.13   0.63   -6.3  -4.57  -4.19  -4.14  -4.09     23   1.06\n",
      "log_lik[28]   -4.7     0.1   0.65  -6.56  -4.76  -4.44  -4.36  -4.27     47   1.03\n",
      "log_lik[29]  -4.83     0.3   0.74  -6.37   -5.5  -4.56  -4.19  -4.11      6   1.23\n",
      "log_lik[30]  -4.83    0.24   0.72  -6.44  -5.33  -4.61  -4.22  -4.12      9   1.14\n",
      "log_lik[31]  -4.82  7.2e-3   0.62  -6.58  -4.95  -4.76  -4.38  -4.29   7393   1.01\n",
      "log_lik[32]  -4.85     0.5   0.92  -6.28   -5.9  -4.42  -4.05  -3.96      3   1.53\n",
      "log_lik[33]  -4.41    0.07   0.64  -6.25  -4.46  -4.19  -4.08  -3.99     82   1.03\n",
      "log_lik[34]  -4.43    0.09   0.61  -6.21  -4.49   -4.2  -4.12  -4.03     42   1.04\n",
      "log_lik[35]  -4.35    0.15   0.65  -6.22  -4.44  -4.07  -3.98  -3.97     18   1.07\n",
      "log_lik[36]  -4.41    0.25    0.7  -5.99  -4.94  -4.19  -3.82  -3.72      8   1.16\n",
      "log_lik[37]  -3.89    0.07   0.62  -5.73  -3.93  -3.66  -3.56  -3.47     76   1.03\n",
      "log_lik[38]  -3.62    0.54   0.96  -4.98  -4.85  -3.17  -2.79   -2.7      3   1.62\n",
      "log_lik[39]  -4.27    0.13   0.64  -5.92   -4.6  -4.13  -3.76  -3.66     26   1.05\n",
      "log_lik[40]  -3.68    0.14   0.67  -5.63  -3.76  -3.38  -3.33  -3.29     23   1.05\n",
      "log_lik[41]  -3.65    0.13   0.63  -5.48  -3.72  -3.36  -3.33  -3.27     25   1.05\n",
      "log_lik[42]  -3.63    0.14   0.63  -5.45  -3.72  -3.35  -3.29  -3.26     21   1.06\n",
      "log_lik[43]  -3.63    0.02   0.61  -5.32   -3.8  -3.55  -3.18  -3.09    920   1.01\n",
      "log_lik[44]  -4.24    0.85   1.32  -6.35  -6.18  -3.53  -3.16  -3.07      2   2.33\n",
      "log_lik[45]  -3.73     0.1   0.63   -5.4  -4.01  -3.61  -3.23  -3.14     39   1.04\n",
      "log_lik[46]  -3.56    0.15   0.64  -5.42  -3.66  -3.28  -3.19  -3.19     17   1.07\n",
      "log_lik[47]  -4.17    0.29   0.74  -5.77  -4.82  -3.91  -3.53  -3.43      6    1.2\n",
      "log_lik[48]  -3.93    0.37   0.77  -5.34  -4.76  -3.62  -3.25  -3.15      4   1.33\n",
      "log_lik[49]  -3.87  7.2e-3    0.6  -5.63  -3.88  -3.74  -3.51  -3.42   6890   1.01\n",
      "log_lik[50]  -4.34    0.48   0.89   -5.8  -5.39  -3.94  -3.56  -3.46      3   1.49\n",
      "log_lik[51]  -1.52  7.0e-3   1.03  -4.29  -1.71  -1.59   -0.8  -0.14  21570    1.0\n",
      "log_lik[52]  -3.52    0.05   0.63  -5.38  -3.55  -3.32  -3.18  -3.09    134   1.02\n",
      "log_lik[53]   -3.6    0.15   0.64  -5.47  -3.68  -3.31  -3.23  -3.22     18   1.07\n",
      "log_lik[54]  -3.96     0.3   0.71  -5.43  -4.62  -3.71  -3.33  -3.24      6   1.22\n",
      "log_lik[55]  -3.55    0.15   0.64  -5.44  -3.63  -3.27  -3.19  -3.18     19   1.06\n",
      "log_lik[56]  -3.87  5.8e-3    0.6  -5.59  -3.86  -3.79   -3.5  -3.41  10426    1.0\n",
      "log_lik[57]  -3.63    0.12   0.63  -5.43   -3.7  -3.34  -3.31  -3.25     26   1.05\n",
      "log_lik[58]  -3.48    0.15   0.65  -5.36  -3.57  -3.19  -3.11   -3.1     18   1.07\n",
      "log_lik[59]  -3.99    0.22   0.67  -5.58  -4.49  -3.78  -3.42  -3.33     10   1.12\n",
      "log_lik[60]  -3.68    0.03   0.64  -5.56  -3.69  -3.51  -3.32  -3.23    611   1.01\n",
      "log_lik[61]  -3.78    0.15   0.64  -5.42  -4.14  -3.63  -3.26  -3.17     19   1.06\n",
      "log_lik[62]  -3.55     0.1   0.62  -5.38  -3.62  -3.29  -3.24  -3.15     37   1.04\n",
      "log_lik[63]  -3.58    0.13   0.64  -5.45  -3.65  -3.28  -3.25  -3.19     26   1.05\n",
      "log_lik[64]  -4.33     0.9   1.39  -6.57   -6.4  -3.58  -3.21  -3.12      2   2.41\n",
      "log_lik[65]  -3.28    0.04   0.61  -5.03   -3.3   -3.1  -2.94  -2.85    289   1.02\n",
      "log_lik[66]  -3.29    0.03    0.6  -5.03  -3.31  -3.12  -2.94  -2.85    368   1.01\n",
      "log_lik[67]  -3.31     0.1   0.63  -5.18  -3.35  -3.05  -2.99  -2.91     42   1.04\n",
      "log_lik[68]  -3.21  6.2e-3   0.61  -5.03  -3.21  -3.11  -2.85  -2.75   9490    1.0\n",
      "log_lik[69]  -2.94    0.15   0.65  -4.86  -3.03  -2.66  -2.57  -2.57     18   1.07\n",
      "log_lik[70]  -4.25    1.39   2.04   -7.7  -7.54  -3.08  -2.71  -2.62      2   3.48\n",
      "log_lik[71]  -3.05     0.1   0.62  -4.91   -3.1  -2.79  -2.74  -2.66     41   1.04\n",
      "log_lik[72]   -2.9    0.15   0.62  -4.69  -2.99  -2.62  -2.53  -2.53     17   1.07\n",
      "log_lik[73]  -3.09    0.02   0.59  -4.74  -3.24   -3.0  -2.66  -2.57   1355   1.01\n",
      "log_lik[74]  -3.11  8.9e-3   0.62  -4.84  -3.27  -3.02  -2.66  -2.57   4752   1.01\n",
      "log_lik[75]  -2.97  6.0e-3   0.58  -4.63  -3.05  -2.93  -2.56  -2.47   9311    1.0\n",
      "log_lik[76]  -3.11    0.19   0.66  -4.69  -3.55  -2.93  -2.56  -2.47     12    1.1\n",
      "log_lik[77]  -2.76    0.12   0.63  -4.59  -2.83  -2.46  -2.45  -2.37     29   1.05\n",
      "log_lik[78]   -2.4    0.06   0.62  -4.25  -2.43  -2.18  -2.06  -1.97    103   1.02\n",
      "lp__         8.1e4  1927.9 2726.6  7.6e4  7.9e4  8.2e4  8.2e4  8.2e4      2  232.6\n",
      "\n",
      "Samples were drawn using NUTS at Sun Apr 26 09:35:05 2020.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "print(fit_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoriyuki/.pyenv/versions/anaconda3-5.3.1/envs/COVID-19/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"sm_const_fit.pkl\", \"wb\") as f:\n",
    "    pickle.dump({'model' : sm_const, 'fit' : fit_const}, f, protocol=-1)\n",
    "    # or with a list\n",
    "    # pickle.dump([model, fit], f, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoriyuki/.pyenv/versions/anaconda3-5.3.1/envs/COVID-19/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"sm_every_fit.pkl\", \"wb\") as f:\n",
    "    pickle.dump({'model' : sm_every, 'fit' : fit_every}, f, protocol=-1)\n",
    "    # or with a list\n",
    "    # pickle.dump([model, fit], f, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load modesl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sm_const_fit.pkl\", \"rb\") as f:\n",
    "    data_dict = pickle.load(f)\n",
    "    # or with a list\n",
    "    # data_list = pickle.load(f)\n",
    "sm_const = data_dict['model']\n",
    "fit_const = data_dict['fit']\n",
    "# fit = data_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sm_every_fit.pkl\", \"rb\") as f:\n",
    "    data_dict = pickle.load(f)\n",
    "    # or with a list\n",
    "    # data_list = pickle.load(f)\n",
    "sm_every = data_dict['model']\n",
    "fit_every = data_dict['fit']\n",
    "# fit = data_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_const = az.from_pystan(fit_const, log_likelihood='log_lik')\n",
    "data_every = az.from_pystan(fit_every, log_likelihood='log_lik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoriyuki/.pyenv/versions/anaconda3-5.3.1/envs/COVID-19/lib/python3.7/site-packages/arviz/stats/stats.py:727: RuntimeWarning: overflow encountered in exp\n",
      "  weights = 1 / np.exp(len_scale - len_scale[:, None]).sum(axis=1)\n",
      "/Users/yoriyuki/.pyenv/versions/anaconda3-5.3.1/envs/COVID-19/lib/python3.7/site-packages/arviz/stats/stats.py:527: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  \"Estimated shape parameter of Pareto distribution is greater than 0.7 for \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 20000 by 78 log-likelihood matrix\n",
       "\n",
       "       Estimate       SE\n",
       "IC_loo  6299.22  1151.73\n",
       "p_loo   1177.17        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "------\n",
       "\n",
       "Pareto k diagnostic values:\n",
       "                         Count   Pct.\n",
       "(-Inf, 0.5]   (good)        3    3.8%\n",
       " (0.5, 0.7]   (ok)          9   11.5%\n",
       "   (0.7, 1]   (bad)        19   24.4%\n",
       "   (1, Inf)   (very bad)   47   60.3%"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo_const = az.loo(data_const, pointwise=True)\n",
    "loo_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoriyuki/.pyenv/versions/anaconda3-5.3.1/envs/COVID-19/lib/python3.7/site-packages/arviz/stats/stats.py:727: RuntimeWarning: overflow encountered in exp\n",
      "  weights = 1 / np.exp(len_scale - len_scale[:, None]).sum(axis=1)\n",
      "/Users/yoriyuki/.pyenv/versions/anaconda3-5.3.1/envs/COVID-19/lib/python3.7/site-packages/numpy/core/_methods.py:38: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "/Users/yoriyuki/.pyenv/versions/anaconda3-5.3.1/envs/COVID-19/lib/python3.7/site-packages/arviz/stats/stats.py:527: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  \"Estimated shape parameter of Pareto distribution is greater than 0.7 for \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 20000 by 78 log-likelihood matrix\n",
       "\n",
       "       Estimate       SE\n",
       "IC_loo   617.99    26.36\n",
       "p_loo     72.13        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "------\n",
       "\n",
       "Pareto k diagnostic values:\n",
       "                         Count   Pct.\n",
       "(-Inf, 0.5]   (good)        3    3.8%\n",
       " (0.5, 0.7]   (ok)          8   10.3%\n",
       "   (0.7, 1]   (bad)        52   66.7%\n",
       "   (1, Inf)   (very bad)   15   19.2%"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo_every = az.loo(data_every, pointwise=True)\n",
    "loo_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoriyuki/.pyenv/versions/anaconda3-5.3.1/envs/COVID-19/lib/python3.7/site-packages/arviz/stats/stats.py:1196: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>waic</th>\n",
       "      <th>p_waic</th>\n",
       "      <th>d_waic</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>waic_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>everyday</th>\n",
       "      <td>0</td>\n",
       "      <td>557.168</td>\n",
       "      <td>41.7203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1410.2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>deviance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>1</td>\n",
       "      <td>7096.43</td>\n",
       "      <td>1575.77</td>\n",
       "      <td>6539.26</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0709</td>\n",
       "      <td>1418.42</td>\n",
       "      <td>True</td>\n",
       "      <td>deviance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rank     waic   p_waic   d_waic weight       se      dse warning  \\\n",
       "everyday    0  557.168  41.7203        0      1   1410.2        0    True   \n",
       "const       1  7096.43  1575.77  6539.26      0  24.0709  1418.42    True   \n",
       "\n",
       "         waic_scale  \n",
       "everyday   deviance  \n",
       "const      deviance  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.compare({'const':data_const, 'everyday':data_every})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fe408b57050>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAFgCAYAAAAxR5cGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5zUxd3A8c9s39vrjd5BBaUJAoqAIvaCvdcYNfaSRBM1T4zmUWMeE7uJoiIKiA2xYUHBroh0UOntaNfr9p3nj9nrBxxc2737vl8vXsz92N0bdn/7+858Z34zSmuNEEIIEc8sbV0BIYQQoqkkmAkhhIh7EsyEEELEPQlmQggh4p4EMyGEEHHP1hIvetJJJ+mPPvqoJV5aCCHikWrrCrR3LdIzy8vLa4mXFUIIIRokaUYhhBBxT4KZEEKIuCfBTAghRNyTYCaEECLuSTATQggR9ySYCSGEiHsSzIQQQsQ9CWZCCCHingQzIYQQcU+CmRBCiLjXImszivZFa01+WYAImgS7jUSXnDZCiNgiVyWxV75gmGVbi7jzreXkFHo5+bDO/M/ph5KV5GzrqgkhRBVJM4q9KqoIcvmLC9mcX0Eoonlv+Q6e+Gwt3mC4rasmhBBVJJiJvdpaUIE/FKl1bP6vuyn1BduoRkIIUZ8EM7FXnVNc9Y4d0jkJt93aBrURQoiGSTATe5XitnP3KQOxWczegj3S3fz19ENJctnbuGZCCFFNJoCIvUp227lkdE/OGNoVXzCMx2mTyR9CiJgjwUzsk8dpw+OUU0UIEbskzSiEECLuNaq5rZTaBJQCYSCktR7ZkpUSQggh9sf+5I6O1VrntVhNhBBCiAMkaUYhhBBxr7HBTAOfKKV+Ukpd29ADlFLXKqUWKaUW5ebmNl8NhRBCiH1obDAbq7U+HDgZuFEpNb7uA7TWz2mtR2qtR2ZlZTVrJYUQQoi9aVQw01pvj/69G5gNjGrJSgkhhBD7Y5/BTCnlUUolVZaBE4CVLV0xIYQQorEaM5uxEzBbKVX5+Bla649atFZCCCHEfthnMNNabwCGtkJdhBBCiAMiU/OFEELEPQlmQggh4p4EMyGEEHFPgpkQQoi4J/t6iGZX5gtSEQijlCItwY7NKm0mIUTLkmAmmlV+mZ+HPvyFd5bmkJbg4P7JhzJuQBaJLjnVhBAtR5rMotkEwxFm/LCFNxdvIxTR5Jb5uWHGYgorAm1dNSFEOyfBTDSbUl+IT3/eVeuY1rAip7iNaiSE6CgkmIlmk+CwMqxHar3j/bMT26A2QoiORIKZaDYuu5Ubj+3PoC7JAFgtipsm9ic7ydnGNRNCtHcyKi+aVadkF9OuHoU3EMZuteBxWkly2du6WkKIdk6CmWh2mYnSExNCtC5JMwohhIh7EsyEEELEPQlmQggh4p4EMyGEEHFPgpkQQoi4J8FMCCFE3JNgJoQQIu5JMBNCCBH3JJgJIYSIexLMhBBCxD0JZkIIIeKeBDMhhBBxT4KZEEKIuCfBTAghRNyTYCaEECLuSTATQggR9ySYCSGEiHsSzIQQQsQ9CWZCCCHingQzIYQQcU+CmRBCiLgnwUwIIUTck2AmhBAi7kkwE0IIEfckmAkhhIh7EsyEEELEPQlmQggh4p4EMyGEEHFPgpkQQoi4J8FMCCFE3JNgJoQQIu5JMBNCCBH3JJgJIYSIexLMhBBCxD0JZkIIIeKeBDMhhBBxT4KZEEKIuNfoYKaUsiqlliil3m/JCgkhhBD7a396ZrcCP7dURYQQQogD1ahgppTqDpwKTGnZ6gghhBD7r7E9s8eAO4HInh6glLpWKbVIKbUoNze3WSonhBBCNMY+g5lS6jRgt9b6p709Tmv9nNZ6pNZ6ZFZWVrNVUAghhNiXxvTMxgJnKKU2Aa8BE5VSr7ZorYQQQoj9sM9gprX+s9a6u9a6N3Ah8LnW+tIWr5kQQgjRSHKfmRBCiLhn258Ha60XAAtapCZCCCHEAZKemRBCiLgnwUwIIUTck2AmhBAi7kkwE0IIEfckmIlmEYloIhHd1tUQQnRQ+zWbUYi6fMEwO4p9vPTNRuxWC1ce1ZvOKU7sVmtbV00I0YFIMBNNsqPYx4n//pJA2CzbOXPhFj69fQLd0txtXDMhREciaUZxwCIRzdRvN1UFMoCKQJh3lm5rw1oJIToiCWaiSZzW+qeQQ1KMQohWJsFMHDCLRXH5kb1IcFQHr9QEO6cP7dqGtRJCdEQyZiaapFOKi3l3TGDO0u3YrYrThnQlK8nZ1tUSQnQwEsxEk9itFrqmurn+mH5tXRUhRAcmaUYhhBBxT4KZEEKIuCfBTAghRNyTYCaEECLuSTATQggR9ySYCSGEiHsSzIQQQsQ9CWZCCCHingQzIYQQcU+CmRBCiLgnwUwIIUTck2AmhBAi7kkwE0IIEfckmAkhhIh7EsyEEELEPQlmQggh4p4EMyGEEHFPgpkQQoi4J8FMCCFE3JNgJoQQIu5JMBNCCBH3JJgJIYSIexLMBADhiKbEGyQYjrR1VYQQYr/Z2roCou0VlPl5b/kOPlm9kxG90rhsTG+ykpxtXS0hhGg0CWYdXLk/xKOfrmH6D1sA+GZdPl+vzWPKFUeQ7nHs8XklviDhiCYtYc+PEUKI1iLBrIMr94d4Y9G2WscWbymiwh9qMJj5Q2HW7y7nHx/9QqkvxDXj+nBUvwxSJKgJIdqQjJl1dAo8TmutQxYFVqtq8OF5pQHOfPobvliTy+IthVw/fTFLtxW3Rk2FEGKPJJh1cGkJDu4+ZWCtY1ce1ZtEZ8Od9i/X5hKoM0lk6jebKPOHWqyOQgixL5Jm7ODsVgsnHtaZ4T3TWLgxn8O6pdAjLYEkl73Bx3dJcdU71i3NhWMPPTkhhGgNEswEyS47yS47/bMT9/nYw7qlMLhbCityTGoxLcHO9RP647BZ9/FMIYRoORLMxH7JTHTy0lVHsCW/glJ/iIFdksj0yDR+IUTbkmAm9ltmopPMRAlgQojYIRNAhBBCxD0JZkIIIeKepBlFmwpHNPllfsJa47RZ97rqSEyrKABlAXdq7bIQolVIz0y0GX8wzI+bCjj9qa858qHPuXrqj2wv8rZ1tfaftxBevwKWvAq+Enj9cljxhikLIVqFBDPRZoq9Qa566Ud2lfgBWLK1iLtnr6DYG2zjmu0nZYVhF8En98ATw2DnCugzHhyetq6ZEB3GPoOZUsqllFqolFqmlFqllPpba1RMtH8lviDeYLjWsR82FOCvcyzmuZLh4FMhqQtU5MNBJ0NyV7DIvXdCtJbG9Mz8wESt9VBgGHCSUmpMy1ZLdARJLjtOW+1TcFiPVBy2OEsYeAth1qUQ9MKoa2D5TFj2mqQZhWhF+5wAorXWQFn0R3v0j27JSon2rcwXpCIQxmm18NTFh/P7N5ZS4g3RL8vDP84ZQmq8rcCvrHD45dBlCCR3g+6jTVnSjEK0GmVi1T4epJQV+AnoDzyttb6rgcdcC1wL0LNnzxGbN29u5qqK9mBnsY8H3l/Nwk0FjOyVxt/OGIRGEQhFcNutZMbrpqD+MrC7TWqxZlkIQxYvbWGNCmZVD1YqFZgN3Ky1Xrmnx40cOVIvWrSoGaon2pOC8gBXT/2RJVuLqo4N6Z7C1KuOIF2WxBLtmwSzFrZfgxNa6yJgAXBSi9RGxIyCsgC5pb5mnVnoC4ZrBTKA5duK8QUje3iGEEI0TmNmM2ZFe2QopdzAJOCXlq6YaBuRiGbd7lKueGkhox/8jBum/9Rs937ZLIoUd+2tZZLdNqwWabQKIZqmMT2zLsB8pdRy4EfgU631+y1bLdFW8sr9XPbCQlbkFBPR8M26fG6btZTC8kCTXzs1wc4j5wzBFg1eNoviH+cMIS2h4b3ThBCisRozm3E5MLwV6iJigDcQZkexr9axhRsL6u0ufSAcNivjBmTy9V0T2VHspXOKixS3XfZCE0I0mazNKGpx2a14HFbKA9U3LvfJ9GBVzZMKTHDaSHDa6NzAjtVCCHGg4uzuVNHSUhPs/PuCYbjs5tRIcdt5/MJhZCTG2b1fQogOZb+m5jeWTM2Pb75gmGJvkHJ/iESnjTSPA7tV2j1CNIHMcmphkmYU9bjsVlx2GccSQsQPaW4LIYSIexLMhBBCxD0JZkIIIeKeBDMhhBBxT4KZEEKIuCfBTAghRNyTYCaEECLuyX1mosXllfnxBsI4bBbSEhw4bNKGapKy3WCxQUJ6tGyHhLS2rpUQbUquKqJFbS2o4IL/fse4R+Yz6dEvmP/rbrzBUFtXK375S+D5ifDN41CcA89NgOWzIFDR1jUTAqXU3W32u2U5K9FSiioCXD99Md+tz6865rBa+PKuY+mcLAsNH5BAOWz8Cl67ELSG7EFw2WxI6tzWNRN7d0DLWfX+0wcXAw8CPYEtwN2bHj51RnNWrDkppcq01olt8bulZyZaTCAUYcW24trHwhFKmnH36g7H4YHOh4E9wfzcbSTYpGHQHkUD2fNAL0ww7AU8Hz3eJEqpy5VSy5VSy5RSryileimlPose+0wp1TP6uKlKqSeUUt8qpTYopc6NHu+ilPpSKbVUKbVSKTVOKfUw4I4em97UOu4vCWaixbjsVkb3Sa91zG231tttWuwHfwm8eBKk9YZTHoWlr8Ky1yTN2D49CCTUOZYQPX7AlFKHAvcAE7XWQ4FbgaeAaVrrIcB04IkaT+kCHA2cBjwcPXYx8LHWehgwFFiqtf4T4NVaD9NaX9KUOh4ImQAiWkyy287fzzyMwhlLWLylkE7JTv59/jBS9xLMguEIheUBNJDgsJLkksBXi7LC5Kch62BwJkPmAFN21L3miXag534eb6yJwJta6zwArXWBUupI4Ozov78CPFLj8e9orSPAaqVUp+ixH4EXlVL26L8vbWKdmkyCmWhRXVLdTLliBP5QBKtSZCQ6sVoaHj4o9QVZ8Gsuf313FUUVAU4Z3IX7zjiUzERnK9c6hjk80OsosEaDfM2yOCCBUJjdpX7mrthJSoKdYw7KIjs2xnS3YFKLDR1vCgXsa7JEzX/313kuWusvlVLjgVOBV5RS/9RaT2tivZpEgplocemexgWjwoogt7y2hMo5Se8v30GfTA83Txwg0/lrqhm8JJA12bZCLyc//hX+UASAriku3rlpLNlJ1QGt3B+iPBDCZbOS3Hpp8rsxY2Y1u90V0eNN8RkwWyn1b611vlIqHfgWuBDTK7sE+HpvL6CU6gXkaK2fV0p5gMOBaUBQKWXXWrf6wLhcIUTMWLW9mLqTa+f/upsyv0wYES3DHwzz9Px1VYEMYHuxjx82FFT9vLvEx73vrOSUx7/i5pmL2VLQOuOT0VmL1wCbMT2lzcA1TZ3NqLVeBfwv8IVSahnwL+AW4Cql1HLgMsw42t4cAyxVSi0BzgEejx5/DljeFhNApGcmYsaA7KR6xw7vmUaCQ05T0TIigDcYrne88lixN8Bdby9n/i+5AHyxJo/LXviBN393FFlJLZ/+jgauZp+Kr7V+GXi5zuGJDTzuyjo/J+7l+Wit7wLuaraK7gfpmYmYkZXo4A8nHITdasbUBndL4cZj+8uu16LFuO1Wrj+mP6rGMG6yy8b4AVkA+IMRFvyaW+s5m/Mr8AbqB0DRtqTJK2JGSoKDq8b24dwRPQiGIyQ4rGTI5A/Rwvpmevjg5nFM+XoDqW47Vx/dl6xEBwBKKbqlutlW6K16vNNmkTHcGCQrgAjREryFZuq8xVq7LGJWMBxBKbBZqgNVJKL5cVMBl7+4EH8ogkXBg2cNZvKwbrgd+/V5HtAKIKLxpGcmRHMrz4NP7oGj7wBPFnz8Z1PO6C8BLYbZrfV7WxaLYliPVL6881h2lfjITHSS7LLvbyATrUCCmRDNTWso2gYvnAAZfSH3VxhzI+gIIBfBeOO0W+lkt9IpNu49E3sgiV8hmltiFlw0AwKlkLMYJt0PWYfIPWExJK/Mz6qcYpZtLSKv1L/vJ4iYJz0zIZpbeR68e7NZADilO3z+APQ5GjIGSJoxBuSV+rnipYWs2l4CQO+MBF6/7shYWfWjXVNKXQmM1Frf1NyvLcFMiOamNUTCcNVcE8xmXw+hgKQZY8TX63KrAhnApvwK3lq8jd9N6IdSMTRP474UBzAn+tN5wBvR8mTuKw60TaUappSyaq3b9H4FSTMK0dwSs+Ds/5q9xhIyouWBkmaMEetzy+sdW7u7jHALzOxuojnAhOifbTXKc/b2pMZQSl2qlFoY3a7lv0qpG5VSj9T49yuVUk/u4bHW6PEypdT9SqkfgHuVUrNrPP94pdTb0fJVSqk1SqkvgLE1HnO6UuoHpdQSpdQ8pVQnpZRFKbVWKZUVfYxFKbVOKZW5r/+TBDPRdP7ShssdmTutOnjVLIs2d/rQrtTtgF08qmetKfkxxg2kRP9uMqXUQOACYGx0C5cwUEb1qvlE/33WHh5bub2LB1iptR4N3A8MrAxCwFXAS0qpLsDfMEHseGBQjd/xNTBGaz0ceA24M7o6/6s1fsckYFnlCv97E7OfnogTZbtg/kNQnlu7LESM6pLiYtpVoxjSPYVBXZJ5+uLhHNSpeim1Ul+Qn3eU8PDcn3lj0da2nCByHlA3nRgAzm3i6x4HjAB+VEotjf7cB9iglBqjlMoADga+2cNj+0ZfJwy8BaDNDcuvAJcqpVKBI4G5wGhggdY6V2sdAGbVqEd34GOl1Argj8Ch0eMvApdHy78BXmrMf0rGzETT+ErMBpHbl0CwAkq2wZjr2rpWQuxRksvOuIOyOLRrChpNusdRa6xs0aZCrpr6Y9XPg7okM+3qUW2xFdEbgKPOMQfwJnByE15XAS9rrf9c66BSVwPnA78As7XWWpk3pt5jo3x1xsleAt4DfMAbWutQ9H3dU/72SeBfWut3lVLHAPcBaK23KqV2KaUmYoJhozb6lJ6ZaJr0vnDBdNjyLexYCpfNgZSm7h0oRMtLT3SQkeisFcjyy/z83ye/1nrc6h0l7C7xtXb1avICxdG/m8NnwLlKqWwApVR6dEuXt4EzgYuo7kHt6bH1aK23A9uBe4Gp0cM/AMcopTKiG3meV+MpKUBOtHxFnZebgkk3vt7YiSUSzETTVOTBvL+CK8VsHPnJPeaYEG2o3B9iZ7GPDbll7C71EY40bnKHBiINTARp5NOb22Tgi+if7jXKk5vyolrr1ZiA80l0y5dPgS5a60JgNdBLa71wb4/dy8tPB7ZGn4fWegemx/UdMA9YXOOx9wFvKKW+AupeNN4FEmlkihFkbUbRVHlrYeYFcMmbEPLDrEvgstmQ2mDjTYgWV+4PMWfpdv767kqCYU2Gx8HMa8fUGhfbE601c1fu5Ibp1dfcflkeZl17JJlN2/Ilhub8txyl1FPAEq31C018nZHAv7XW4xr9HAlmoknCYQhVgCMRIpHqcizdryM6lJ3FPo7+x+eEanSnhvVI5cUrRzZq1/MSb5D1uWXMWLiFgzslMXlYV7KSmnxDdbv/QiilfgLKgeO11gc8a0Yp9SfgeuASrfVed7yuSSaAiKaxWsGaVL8sRBsp8wdrBTKANbtKCYUb13BPdtsZ3jONod1TsVjafQxqNlrrEc30Og8DD+/v82TMTAjRriS77KS4a9/XN/GQbBL2c6V7CWTxRYKZEKJdSfc4mHnNaA7tmozDauHkwzrzP6cNItElN663Z5JmFEK0KzarhUFdU5j2m1GEtcZtt5Ikgazdk2AmhGiXMlr/JmfRhiTNKGKbr6jhshBC1CDBTMSusl3w/h1Qsr12WQgh6pA0o4hd4ZDZqfmlU8Dugop8c2O2EPspEtHklwfQaBIdNhKcculrb+QTFbErpRtc8jo8dYT5+aoPIa13m1apJUQimrxyP8UVQTxOG4lOG8lumbDQXMr9IX7cVMC976wkr8zPOYd3547jD5IxtXZGgpmIXWW74O1rISEdrE549xa44j1I7trWNWtWWwoqOO+/35Fb6kcpuH5CP64b35eUhLoLposDUVgR4DdTf6xaX3H6D1vomuriuvH9sFllpKW9kE9SxK5wyGxq+dvP4befmaDWztKMJd4g97+/itzonllawzML1lPkDbZxzdqPlTkl9RYKnrtyJyU+eY/bk332zJRSPYBpQGcgAjyntX68pSsmBCnd4OI3wZVs1nqsLLcjvlCYdbvL6x3fVeKnV4anDWoUO8r8Qcr8YRSQ5Dzwca6+mfXfx0O7puC2S2KqPWlMzywE/F5rPRAYA9yolBq0j+cI0TzcKdWLFtcstxMpLjsnH9a51jGX3UKvjIQ2qlFsyC/384+5v3L0w58z/pH5PDl/HYXldTddbpzsZCfXjOtTder0zfRw23EDcO/n8lYitu2zaRLdj2ZHtFyqlPoZ6IbZ90YI0QROu5Vrx/elPBDivWU76J7m5sGzBpOW0LEngHy/oYBXvt8MQCiieXbBesYNyOSofpn7/VqpCQ5unjiA34ztgz8cweOwkdW07VxEDNqvfrZSqjcwHLN7qBCiGWQkOrnnlEHcMnEAVovq8LPswpEIn67aVe/4F7/m7jWY+YJhyv0hPE4bLnvtXley2y4zRNu5Rk8AUUolAm8Bt2mtSxr492uVUouUUotyc3Obs45CtHtuh5XsZFeHD2QAVouFCQfXD1pj+2fs8Tm5pT4envsLl0z5gYc+/Jndpb6WrKKIQY0KZkopOyaQTddav93QY7TWz2mtR2qtR2ZlZTVnHYUQHcz4AVmcOawrSoHVorhsTC8O65bS4GMLywPcNmspU7/dxC87S3n5u83cOnMphRUHNsYm4lNjZjMq4AXgZ631v1q+SkKIji4j0cn9kw/jrpMPQQEep22PK9/7gmG+WZdf69h3G/LxBsKkdex5NB1KY8bMxgKXASuUUkujx+7WWn/YctUSQnR0jR3nslgUiU4bZf5Q1TGPw4pVNtfsUPaZZtRaf621VlrrIVrrYdE/EsiEEDEh1W3nL6cNrHXs3tMGkSoTPjoUuWtQCBHXnHYrpwzuwpH9Mlmzq5SDshNJ8zhw2uU+so5EglkMyS31U+4P4bBZZLFZQGtNbqmfb9fnEwhHmHBQFpmJTkkfiXqSXHaSXHZ6pssgWUclwSxG7CjycsmUH9iQV45S8IcTDuaK0V1ITIguxRPyg61jTdvOLfVz+lNfs6vErFuY4rYz99ZxdE11t3HNRFvILfVRVBHEZbeS5LKRKgsxixpkoeEY4A2GefLztWzIM2v09c9K5Nx+Gvf2hRD0QtEW2PIdBOqv4deefbRqZ1UgAyj2Bpn23WYidVeNFe3e9iIvZz3zLcf/+0vGPTKfhz785YCXtxLtkwSzGOANhFm1vfo+9CtGZJC89i2sM86BH6eYzSk/vgciob28SvtT0sDK8cUVZoNF0UyCfvOnbrktqhKOsLvUx+5SHxU1ZiZ6A2H+PW8N2wq9VcdmLdrKjmJvQy8jOigJZjEg2WXjlMFdqn7+68dbWN7lfPTAM+CTeyHkhctmg6v2TaNlviC5pX4CoUhrV7lVTB7WDaet+hS1KLjq6D5YLXLaNougH3Yugx1LTQagstwG2+yU+ILMWZrDSY99xbh/zOeRj3+loNzUwxsMs2Znab3nbM6vaO1qihgmV4UYYLNaOG9kd648qjceh5Wx/TIYlm1BbfsRLDbwFsKO5VVpRq01Wwsq+MMby7nwue94bN4a8sva1z5fANlJTj68ZRznHN6N04d04f2bx9FdxsuaT7AclrwK006HL/4JL58GS15pk3T2rmIff3hjOQXlAfyhCFO/3cRHK3cRiWhSXDZOH1p7Q1abRTGkR2qr11PELqV186dsRo4cqRctWtTsr9veeQNhSv1BkvDhWvw8auWbcNVc+PKfsPFLuOpDcKWQW+rnjKe+Zkdx9fpzl47pyT2nDMTtaH9zevzBMBrqLR5bV1FFgM35Fcz/dTcjeqVxaJdk0mWtw73zFsGrZ0POT9D1cJMBcLd+kJj23Sb+Z86qWsfGD8jkmUsOJ9Flp6Dcz5SvNjLrx61kJjr52+RDGdojrvYkkym4LSxuzoSOwO2wRvdYcsERV8PIK83uyuP/COPuqEozlviCtQIZwJwl27ll4oB2Gcwac79QIBTh7cU53P9+9c5E547ozl9OG0iKW2a9NSjoh7w1sGulObd2rzI/dxna6jNnG1p3cUSvtKoGTLrHya3HDeDKsb2xKEWmNFJEHZJmjFUJ6eDJql8GEuzWentUdkl1YWmN+6/CQSjPA19J7XIbK/IGeGzemlrH3lq8jQp/uI1qtA81J/O01cSeyjTjwMlwx88w6CxYPK1N0oy9MzxcOrpn1Xk9vEcqF4/uic1afYly2q1kJ7kkkIkGtb9mfAfgcdr43YR+PLtgPQAOq4UHzxrcOl9ybyE8PhRO/F/oOtzMtLxwBvSZAG05MUODv85EGK0h3AJp9CYrz4OtP0Dvo02DYNtC6HlU66f3EtLhuL+assMDJz5YfbyVpXsc3HnSIdx4bH9CEU2C00qGR4KWaDwJZnEo2W3nuvF9OX9kD7YXeemX5Wm9G0htTph0H7x/u/n5kNOh8+C2DWSYFSCuPKo3//1yQ9Wxcf0z8MRa2jUSht2r4bWL4Zg/m4k9G+bDLUv3/dyW4MlouNwG9mcDzWJvkG2FFXy0cieHdUthRK806bF1cDH2TReNlZrgIDXBQZ9MzwE9X2tNsTeI01Y5TtdI9gToMar65x6jwdr2Y1Juh5XrJvRjcPcUPlyxgzF9MjhlSBfSPG1ft1osVtOjPekR+OhOc+zaBW3SG4pX4Yhm/i+7uW1WdQNg/EFZPHbBUNKlN9dhSTDrgArLA8z7eRevL9pKz3QPt00aQPc0N6ruQFxDvIUmtXjIadBtBHx6L3Q+rO3TjJhU1WlDunLCoE7YrZbG/X/aQsgPm76s/nnj15DWp01mEcajgvIA//fJr7WOfbkmlzJfSIJZBybBrIMJhSPMXprD/e+ZWX8/birkizW7+fCWcWQnu/b9AjYnnD/N9C6sdpNijIE0Y00OWwyvll6ZZtwwH677Anathg//AEPOb+uaxQ2Nrjc+CiCrnHVssXMFEq2isCLI9O831zqWVxYgp6iRSwO5UqDfRPBk1i6LxrFYocswuG0FZHGKMAoAACAASURBVB9qeri3rZQ0435IS3Bw/YR+tY4N7pZCkkva5h2ZfPodjM2iSEtwALWnXyc69+NUsFgbLovGcSVXl60de5ufA2G3Wjjr8G70zfLw9uIchvZIZfLQrmTIBJAOTYJZB5PmcfCX0wdx3rPfEQibVM2kgdlyIRBxJS3BwTEHZzO2fyY2i4rd8VHRaiSYdUAHd0piwR+PYfGWQrqluumZnkB6rM36E6IR7FYZKRGGBLNWlFfmZ0NuGSW+EEO6pZDRRrsmu+xWuqa6ZZNLIUS7IcGsleSV+bnixYVV+5aluO18cPPRdJdt3psm6AO7q35ZtDmtNXllAfyhMA6rhXSPo9byVEI0JzmzWsnybUW1NuAs9gZ59ov1BEIxunZgPCjZDuvmgb+suuyrv++VaBsb88o57z/fcvQ/5nPqE1+zeEshwbCc76JlSDBrJbtL6+83tqPYRzAsN8cckECFCV6zLoHvnjZ7cX1yL2i5WMaC/DI/N89cwqboBpq5ZX5+O20RheX1dw8XojlImrGVjBuQhdNmqbrZUyn4/QkHUREIUREIk55gxyopmMZzJMCgM2HXKljwoFko9+bFsopGjAhFdK1MBECJN0RFUBobomXI1bOVZHocvHvTWCYNzGZ0n3Q+unUcP2ws4JQnvuaMp77m7SU5FFcE2rqa8SVQBus+NfdqBcphwwJJM8YIm0UxuM4eZWkJdhIasTedEAdCglkLKigPsGp7MZ+u3klhRYDeGR4eu2AYz18+ktxSP/e/t5rcUj87in388c3lbC6oaOsqx4/KNGMkArevhuPvhwUPS5oxRmQkOnnyouEMyE4EoEuKi5nXjAZgZ7GX/LL6aXchmkLSjC2koDzAX95ZyQcrdgDgtFl46/qjOKxbCuFIhLeX5NR7zocrdjCku6TJGsWRAAPPgENOhYQMOPwKGH6ppBljSO9MDzOvHUMgFMFpU+wo9nPef79jc34Fh3VL5plLRtBTZvOKZiI9sxZSWB6oCmRgNo68791VFFUEsFosDGsgaA3uJhfi/eJONYGsblnEjMxEJ11T3YQ1XPnSQjZHJ4SszCnh5hmLKSiX1LpoHhLMWkiJr/6srdwyP8HoElKnDO7C8J7VwWvcgExG922+xWZzS318unoXHyzfzu4SHxFZUly0IW8gTF5Z7cC1bFtx1fdBiKaSNGML6ZbmJsPjIL9Gy/OiUT2ji/xCZpKTKZePpMwfQilFotPWbEtK7S71cfYz37Kt0KyEn+Fx8P4tR9MlRVb8EG3DZbeS7LJR4gtVHTuoU2KbrIAj2ifpmTVCuT+ELximzB9ifW4ZT89fx9yVO8jbyyB2psfJ7BvGcsbQLgzpnsL9ZxzK+SN71FoBISPRSa8MT7OvjThv9a6qQAaQXx7g1e83S+9MtJm0BDv/uXQEKW6zS0CXFBfPXDwCj8NGUUUAreXcFE0jPTNMsAqEIqQm2Gutvl3qC/LzjlL+++V6BndLYUTPNC5/aSGV37vhPVOZcvnIqhXny/0hSnxBCsoCZCY56ZTs5KGzh+APhUlxO1qtFVo3nVN5TKMBaQmL1uewWTmiTxqf3j4eXyhCosNCRTDCX95Zyab8cs4/ogfHD+xEmix4LQ5Qhw5moXCEzQUVPPLRL+SW+rlsTC+OOSS7KhX4685Szv/vdwCMH5DFPz/5lZoNyCVbithd6icj0Yk3GGLuyp3c9dZywhGNy27h5atGcUTvdDz7s1dYM5g8rCtPfr62anURpeDKo3pjjaHdoEXHY7dayU4295ntLvVx1tPfkhvNbizaXMi9pw7kyrG9scl5Kg5Ahz5r8ssDTH7qGz5etYvFW4q4/fVlzP9lN1prvIEQz3+1oeqxdqsFX53VC7qnuXHZLOwu8VFQHuSe2SsIR1N5vmCEO15fVmvMrLV0Snbx3s1Hc/JhnTluYDazbzhKpkCLmJJT6K0KZJWm/7BFlrsSB6xDB7OVOcWU+UO1jr3y3WaKKoJYLYrUhOqUxyerdnLJ6F5VP3dPc/P0JYdz51vLGfXgZ+wq9lUtVVVpe7GXSBuMBbjsVg7pnMyj5w/liQuHM6xHWqv3DoXYmyRX/R220xIc2GRCiDhAHTqYNTTpIivJid2qcNis3HhsfxKjQWDBmlwSHFZevXo0pw7uwv+dN5QH3lvNj5sKAbPFS6+M2r2f8QMycTXX8j3+MvOnbnkvEhw2CWIiJqV7HBw/KLvqZ4fVwv+cPlDGzMQBUy0xi2jkyJF60aJFzf66zS2/zM+NMxbz/YYCADwOK+/edDT9okvwhMIR8soCfLs+j2SXnaE9UslKcuIPhinyBhn94GdVrzWwSxJ/P3Mwj89bw4qcYsYNyOSeUwfRKbkZ9tfyl8PGL0BHoO8E2PhVtHwMOBOb/vpCtIH8cj9b8ivYVuhlRK800j2O5mv8xR7pcrawDhnMvIEw3mCYZJeNYm+QLQUV5JUFGNw9hQyPo1FbseeV+bnwue9Zt7u6hzQgO5FXrh6FRSkSHFYSG0ilHJCKQvjhWfjyETj0bFj7KVz9CSRkQmIWVBSAxQau5Ob5fc0pEoGQ16xqX7MsRMciwayFdYg0o9YaXzCM1prtRV7++u5KrnxpIS9+sxGlYHjPNI4f1InOya5GBTIwy/Q8ceFwMhNNWsTjsPKnkw8hzeMgO9nVfIEMICENjrwJeoyBlW/BZbPhs/thzVzwlcCcG+Hn98AfYyvGRyJQsAHWfmJWtS/caMqxVk8hRNxr9wMqBeV+Pl29i89/yeWO4w/immmL2BJdnX75tmJyS/z8/sSDDyi9cVCnRD68dRwV/jBuh5XUBDtOWwukSfzlsOlr2PoDZPSDLd9Br6Pg3Zvhi0fAWwjH3g22ZkhpNqdguVnZ/qO74MibYdkMyOhv0qNCCNGM2nXPrMQb5IH3fuaut1bw6eqdFHkDVYGs0qyftlLiPbDpwDarhewkF70zPXRKdrVMIAMIB2DHUjj6drj2Swh6YfB5kNQFirfCoWdBWh+zr1cscSbBsEtg2MXw3ZNgscLFs8Cd1tY1E0K0M+26Z1YRCDFnmdlqJaLB2UAKMSvRiUXFeDo7IQ1GXw9oM+FjxJXw7i0mXTf4fFjyCvQ8EgadYQJIrIhEoGwXrPkYXClQttuM9x18crPUsyIQIrfUz+e/7KZ3pofB3VLIjK7GIoToWNp1MEMpbBYLgejK3N9vLOD8kT14fdFWAKwWxf2TDyMjsXo6cH6Zn4LyAGGtyUx0xs7FMaFGb8bqhAHHw8R7IK039BwDXYbEbpoxvR9c+ib8+CL8OMXUvRmszCnmwue+p3LJydF90njmkhFVy4sJITqOdj2bscIf4pkF63hq/nrA3MvyytWjSHbb2ZRXzpAeqaS57SRE78XKK/NzzbRFLNlSBJjZiTOuGU1WUowFCTATP+xuk1qsWY413iJzG0FCeu1yExWU+/nN1EUs3VpU6/hHt43jkM4xOKtTxK5wGAKlZk+8muXmFePpn/jXrntmCU4bVx/dl2MPyebb9fkc2TeDflmJpHkcDOxS/4L33fr8qkAGsHZ3GbOX5HDNuL61FiCOCTWn4cfilPxKNS8KzXiBCEfMws51+YKyP5bYD5EIFKyFOTfBBa+YBtd7t8D5r0BS57aundgP7TqYAaR5HIzwpDOi1757A7/sLKl37OcdpYQjGps1xoJZB5fucXDN+D7c+eaKqmPdUt10S43BXrSIXRYL2D1QuhOmTAJfMXQbAard3rzdbsXNbEZvIERZA7s3N6fTh3atd+yCI2rvQSZig9WiOGFQZ168ciSTBmZz3fi+vHX9UbGZEhaxLbkrnPQQFG8zk6rO/I9ZjEDElZgfMwuGw2wt8PLYvLWUeINcO74vh3VPIbk5b0qOKvUF+X5DAf/8+BdCYc0Nx/Zn0sDsWgsOi9hTEQhht1oafcN7S8gr8/PtujyWbi3i9KFd6ZvpIUXOm9gXiUD+GnjhBDNRqXy3WaHm8nebO80oqZ0WFvNpxrzSAKc+8TXe6PYrC9bk8to1YxjTL6PBxxdXBFifW86cZdsZ0j2FCQdlNXpGYpLLzqSB2QzvmYrWJpUl27rHjkAoTG6pn7krd5LitjPh4Cyyk1wkONr2NC4oD3DLzCV8uz4fgBe/2cTDZw/m3BHdpVcf6yrTjIecBsffb+7hXPCQpBnj0D6vAkqpF4HTgN1a68Navkq1fbk2tyqQVZry9QYGd0+ptyJ8KBxh7sqd/Ont6nGU0X3SePbSEaR7GhfQlFKxMx1f1LKt0MvJj39VtdVOt1Q3s288iuw2Ti2W+UJVgazSY/PWctzA7Pad9vSXgQ6DPdGsuVlZtsZZIEjtASc+WD1BqWZZxI3GNBunAie1cD32KKOBIJThcTa471FhRYAnPltb69gPGwsp9dWf9daheIugcBMEK2qX44g/GObp+etq7RmXU+RlYXTHg7akqZ+qD+9P+t5bZBaLrlEOhiLkl/nxBsJ7f+4BikT2UL+KfFOHuuV6LxCGncvh8aGQvxY2LDDlitwWqW+La6FZt6L17DOYaa2/BNrsijG0RyoDsqu3OUly2rhxYn+cDa6lqGjoO9r622NGledVXwxqlltTJAI5P8GTI8z6jgufg6dGmvUe20IkbP7ULe/raZp6PXSAigaOtbZEl42RvWsv0XXTsf1Ja8yYWaDCLBI95Tgoz4Ulr8KU4wiWF3LV1IXc994qdhZ7m62uRRVmS6M731rOq99vJq+0xm7P3kKYeTEsfN7M6vvobgj5zbkL5vz1RReJtlghcwB0GQb/OQpmXQJH/BZszZjViEQaLre0igIo2W5+Z82yiGnNltBXSl2rlFqklFqUm9t8rbOsJCczrhnDy1cdwRMXDmfe7yfQNaXh1E1agp2bJ/avdWxErzSSXW0wpuIrNheoH/5jlnR6/lhY+aa5eLUmiwW6DofDr4Dp58H8/zWztewtlP6KRMxFsW4ZTODKXwd5ayEcMuX8tY0KaG6Hlesn9KPm7X7JLhvjB+xl1llFgfkc6pabWYbHyX8uHcFDZw/mvJHdmXnNaCYP69q48TJHAvSfaMr/GgSf3EPFmDuY/uM2lm8rYdaPW7lq6o+1g84BCoUjvLt0Oxc//wNv/rSNe99ZyTWvLCK/PPraFjuMvg4W/C88ezSM/4M5b9fNg+IcePYo2PQlhALm8fYEOPTM6s/v0LPB0Uz3PFYUwPrPq3utleWWFvTCspnwn7FQsM7sTvHcMWY1GxHTmu0qr7V+DngOzGzG5npdMAFtwsHZ+3yczWrh1CFdGNApkbcX5zC8ZxrHDcxu9HhZk5Xng1JmhYuQHybdB29eZfYhS+8HB59qLl6tTVkgocaEGXeaaVk3VtBrVhipW64rEoGC9fD1Y3DCAyZN9fVjcPzfwJMJ/hL4/O+w8UszLvHJPdDzKDjz6UYtPtw3K5H3bz6aKV9tJNVt5+pxfchKrNP70dp8BhUF8NWjkHmQWYj5q0ch62AYNNmsE9nMMhOdXDSqJxce0WP/b7B3JMGAE82edQ4P/t7HMv3l6nS5LxjBH2p6D7SwIsDspTkcd3A6n/1aQI90N+luC6XekEnnOxOh77GQ2AmKt5jGxqhrYfZ1pseV0d/cg2VzmAC2Yxm8fxuMuR52/wwvnQQ3LqyeBVi605wvab1Ng66yvKf3p/KzAzNNfsa5MPZ20whZPBVu+unAU4DeQjPRw+aoXa7L7jaLeK96B546wnxPLptj9gsUMa3dfUKpCQ5G9clgVJ+GZzu2mIoCeP92SOsFE+6CL/8Jo39nWq+Bcug9rvbiupGI6TVVCvnNl92dWrvcVJVpxq/+CZOfhu1LYeYFcPvPpm774isxreLuI8GValrp3UdCSvf6j9VhU+/VsyHvF7OXWcZBVCV63Wlw2r9h2mSYcwNkD4Iznmz0Kvoep41Du6bwyLlDUFC/51OcA4EyyBgAQZ+5f+i9W0xqNW8NXPsFqOgp7y02S2u5Uszn4C0EZ0rtz+QA7HcgC1TA6jkmkE24C1a8Qdr7v+Wd305n9KMLGdUnncdPyiDZUgwkQNEWsDr2b9q4vxScSditiunndydQmMNz2T24dLCHBP8uQrZooPQWwswLIRyEsbeZhscFr8Ln90PIjz70HHzWRF74fC1KKa4b0R/r5P+gDj4JIkH02nmUhSw8M/cXLj88jc7f/BW1/jPzGu/fZtYOvXyOec+1hrKdZp1Rd5opF242qUurwwTPM5425wmY3RaSOjX+/1y22wSghHQTVN++Fib9FVJ7mQbmpPug82Dzu+qy2EzQ3bbQ9FaTu5h6ipgm84abi80Z3erkKXhqBBx5I7x6NiR3M1N+U3vA5m/Ml8xXDBsXVI9FhIOwcwXMOB/Kck2Lt7LcWEF/w+XKNOM1C2DQmWbfs6vn1U4zRsLm4l9ZLt5m6gkQCcHnD8DU0+Cbx+CNK8xgf0PpUqsdsgfCCX+HbYtMWuiS18GTVf3aFfnm9ZWCkhwzYaCR42aEQ+Arxm61YCNSO23oKzYp1BdOgHWfwrQzzOr8WYfA7lVw8euw+h2zZY6v2Fw8Z18HhRvM+/z2dWbz0D1N3IiEzey9uuWmqkwznj8NjroFfeVc9ORncPrzmTQwi5cu6Ef6h9dgm3GuaYi8cAJ8cm/1/z0cNmV/We1ypeJt8N0z4C0iJVyIe+lUUl+bzPUZS+g653xSP76V9MpTwWI35+3Vn5jAesmbMPUU8x4eeRMqVIGrdDNHdrVgDZbhK80n0P9E0+jyZLG+04kMeeRHnv1iPac/v5wdo+5GJ3aCF0805/r506p7xYEyeH4izH/QfCahgPnMPr4Hlr8Ou1aaRlilnMXV6U1ocNJMFV+JaTDN+5v5vblrTEPspVPgheNh1yrTcFENtOUr04yrZ8M5L5oxwZdOkTRjHNhnMFNKzQS+Aw5WSm1TSl3d8tWKQw6PWb0+o79pCa77HE7+p7n58ohrYciFJhB8+Ef4aSq8cpaZVRiJmJagJ9P8/Pyx8PJppmXY2F6Crwh+nmN+r6+kulwpIR26DjNppMqyJXrTeSRsei3bFpovsrcQXr/ctNDz1sCsS81FrTy3urc58IyG06WRiPk/fP6AeR9sLnjnhuqg7S+Bzx6ATofBnZug8xD4/jlzvJK30AT3uuVIGPJ+NUG1ZDvk/gwvnw4lO8y/u1JMoyG9r2kIHPNnWDjF/B8OOsk0NjZ/ay6s790B3gLz54XjzQXbajOpWK1NUPCXVge2yrG+n98zgaKy7Ku//NkBSe5m0ozORJTDDV8+gvuVk3nsSC+292+FUx41wfe5CWYdzhP+Xh0UKvLMLMJ188wYz+NDzd53kbC5+BduMmnu925BTT0V1e9YdP9JJH10C3gLiFz2DpbKtT2didD/OEjraz5fqx0m/gUufRuO+TN66EWo/4zl4JzZXOhZTOLzYyB/PZGIJr/Mz61vrKp6yxxWC5FIGBWONqwiIfOn8gEWmxm7XfQCPDYYfnrJ/J5lM01PNbUnLJlmjp37Enz9r+rxV38pLHsNZlxggvdPU835WvnvVjuc8k9Y+ir8X3+Y/3c443GIBE224Jg/m9dv6PtVmWb8zScw8FSzXuOVH0Ao2tjzldQOnCJmNGY240Va6y5aa7vWurvW+oXWqFjcqSgwe4wVb4MxN8CHvzerbzs84HCbi8+VH5jewaf/A1d+aI4Fy80XxOaC8XeaVmo4CCc/Unuca28iEfj0LzD9XDM2NOcGM0YRil5IQnUmD5Rsh/XzzIW5fLeZQffKWfDNE/DGVeZCULDBjBkMPA02f21a0jYXrPmodvCpqTLN2GUY/OZjuGpu9BaAGmnG0/8N5001rfnzp8HYW6ovciXb4a1rYfdq04OrLIeDZuzClWrq8dwxpoeS2Ln2TgEhvwlQYC7+qT3gotfgrOfMpJMLXjF1XPUmbF8OF043n5vdDcfeA1MmQtEmsyLEcxPMuBGYXujmb+Cd38G8v5qAGCiv7s36SvYe2HzFpmfhLaxRrjOZobKn7EpBHX8/JHXFPu0081679pJutjnNpI03roBnj4SRv4EuQ82/KWUaDCc+aAKEjkB6X1TuL+bf/aVYijZXX6jBnK+VF3lPppnUkdQZnInsCCZQcvy/SPzqAVI/vZ3SsX/ml0Cm+eiBSI1e7YOn9KLrj/8w58P135nNY9/8TfW5Y3OZgFK5bVGnwVAYfb83fgH56+H21dDrSBhwAtzxc3Wa0e6B/pPM+Oxjg81ncsRvq8e17G6TananmlT6Kf8H088372PPo8x3ZdcKs+ltQxKzzTlsc5nX2r4Yvn3SfMZr5poMhQS0mCNpxqYozzdBA0xLePjF5gI+8V5zEU3vVz1ZIhKEnCWm3G+iuTg/NdJcZDbMN/fsfHI39D3GpOWmTW58mjEhHX77ubnwf/+0SSPmLDYt2IoCWDqjuncUqDCt+Ncuge+fgWlnwiGnmjG9BQ+aHoony1wkrQ446GQziePEB+H2VeaCsa8047kvmgthp0Oj5RozDj1Z1eveWe0w/WwznrH7ZxNwLFZ48STzJ+dHc0FR0dM0qTNM+lt0MkGFGX/zmItpVZpRWeC2FfDrXPPcbiNNb+bgk+HLR83zOg+GbsNh5kWmwWBzm+DkSjWBcspxkNKjekzRlWRa68MvNfuxHXmT6bms+9RMVf/lg7331LxFJlB++5T5LJ4/Fgo2sMel5CLh6rTWiQ/B21ebwH3tF+Z31EwzOpJg0Fmm3GWYmeDy9KjoTNH15u/vnjb/z1HXmvprDb//FQZfAO/dWjt9V1eNdHSy241WNS4ZykK/rEQsFkWGx8HNEwdU/dMf3tvIjtF3E75yLnQaBBe/Bue/WjvNOPUUc75c8Cp0HwEf3AbH3QdXvA/v3gy5a8HqMj1GT1b152GxmEkqA04w70Nittkjr3JM2lcCr54FjkRz3pbtguxDTAProhkmS7KnNGOlyoCuLKbO3z5p0qBvX2veSyWXzlgT82sz7kkoEkEBCoW3vIRfCyKkexx0codxe1phSxRvkcnJ5ywyg9rv3WoukkdcYzbSDJSbYFDZcyjLhccHw/F/NxfS7UtN6m7BQ+Z5Zz8Hi6fB+LvAX2ym9I//Y+N6Z74iWDIDPv6z2aRz8jOm59JngukNrXzDjJl1ji7g4isxF/4f/gP9jjNpq5dONi3V33xsBuv9JXDaY6YVe86L1ReUigLzRW6OySnhMOT/Cs8fZ4JMv+Ph3Cnwz77mgn7Ko3D45dWz53J/Mf+vzkOgdLupx5UfmgH6yvc4EjI/1yyDCeZv/db0mnuMMum3BQ/Dif9rgt3iV6Hb4eaCBfC7b0wwVqo6zfjiieZ3jr3V9HLm3WfScus+g+MfMHVt6H3xl8Paj83EA0Cf9DAlB5/Hv77cRWqCnQtH9aBTkguLRZmL89y7TE/wkjdNT3vMDeaCndy1/gSQ0l3w9BEmkHU/Avodg17wMCrnJxhwEnrYRah598Fl75jGDhqyBpr3pSLfjEM2cmKFLtyMemIo/vH3EHFn4P7odiLXzOfzkm6U+0KM6ZtBTpGXGQu3cHCnJM48vCtZiTXGZstyzfvnyTDlwo0mne5MhoKNptHgSAK70zQUHYngbmDmqb8UlkyHj+6CI2+GZTNMWvviWeZ8D3phx3JI6WbO2R3LzYSlxE7RyT5F5nc2No3vL4V3bjTp+6yD4befHchO6bIuXguLu2DmD5pB7ie/3U2vdA/nHqTwr3iHH5JPYkCqhYwtc1FDL8SR1AqzGQs3mQtc6U7TA7vqI3MBbGiTzFDABB2b0/QEvAWw4g3Tyga4YCb0HGV6GlqbgNPQF7kBuiIf9exYysb+iXDvCaT88KgZ35h6innAhTNM0KpsZZdsN+NNRZtNOjN/vfnCXzQDFr4A/SaYi0ByN3PBsbmrg0Jz0tq8h89NMKnEKz8w78fu1ZDRD3atht98ZGY9Wu1mtuJX/zKTWEK+aPnP1b2zfakoNIHR4YGKIiAM7nQTsHJ/NeNn2YeawFqyDa753Mx+85WaBsGKt8x7tHQm9D4a5v7RjMP1PNJMMNnTvnK+Ylg2yzweCB/9ez5NPY/r39qA1ub+yI9uG0+n5OjnU7bbNCxSupuyjux59qK3CNZ8bCaRWOxEdq5Eh/xYp59t/svX/YArtQsWd4r5f4VDB77/na/ETNpJ6gLKQqQ4h/c3am55ZyMAPdLdvHPDWNISHCYw163nrEvBk21Sza+eA0PON71Dd4ppMDT2dpFIxJyXO5eb3lnpTjN2mN7fBEp/WXSmavT/GQ7W/06G/NU3eNcs1+UvhV8/ND2yvseaFOiRN8HRt+/vJrMSzFpY3PWVraU5OOf8losHOjitnwW1fSmuz/7CmHX/ouuc83D+9BxKN9OqEL5i80UJ+WuXKzmTzWA5RC/+Xfe827PNYVrXrhRTLt1pLtynPmoG2V+/2HxxwFxcGxnIAPLCHoqu+pJZZcO57I0cgsfci14+y7yOxWpSW4HoDLfKNGMkbMYkKm8bOGeKaW2OuBxSe5sLqVJmQkVLBDIwdZp+jvkdl8wy73FKD9M7vPgNc3+YzV2d0knpZqZXezJqlBsZyMD0mB2eaDk1mi6KXmPcqehhlxI8dyqhC2ehB19QO8146DlmzM2VAoedY2afbv7WzBTd8h388v4e04zaWwQf3UnFpIfxnzkF6zf/Ymx6adUN34UVQb5em1f9hMTs6lsfErP3Pg3fnWreJ08WEWcKIVc61tcvJdBnEqHuR5Lw8on4S6PrRtoT9juQaa3JLfWzu9SH1+IxaUF3Kn6rh/+stlcFMoCtBV6+31BQP5CBaexNug9+/QAe6WPGZPtOrO7h7M99jxaLGYMbcIL5PD3ZULITNn1lvkPrPzd/Kmd11v1OVhTAkldMb71muSGVacbjHzBjvBfNNN91STPGnLi6zywS0VQEwyTnraXr7LNMYBn/ByKT7sf56b2gLJTcuJJlwJwQKwAAGdtJREFUuxTjmpppjETMGNfM802KZucKWDUbznvZpGW8RWZm3o6l5v6tzx8wLc+LX29cCi6tN1z/rbl464gZ02nshI86lmwp4o7Xl1HmD3FwpyQqystIWT2HyOXvYXEmm9RZ6U5z4XckmNmIh5xqft/wy8ykiMrfvX+tzaaxJZixRVcKJGSaC9zx95t6WqwmBehMrn2ha6EdtgtUKuv7/I6r/70Up9XC8xdeTy9SqLoDrmbjwmozKbrjH4CRV8FPL5uLoW54yaMilYztukXM+cVLN0siY65fzJzV5XyxZkv1W9GU3Rlq3PxbrJJJOfJW1vQ4H6dN0WvjLMq0iz3c5r5XFf4Qi7cU8pc5q8gt9XPeiO7cNLE/GYlOIhpW5NRfUaXMv4c9B21Oc84ndTG9qqxDzDl3oPf1WSzVDRMdMvc1LngIDjkDfnnXpOv7TGj4uf5SMwlrzccmLblqtuldN9QwcnhMY6/HGHO+VZZl/caYE1dpRq01by/OYVLSJlJmnAqpvdBXvIeafo65WAfKKB91K9axN+NK3o8W+55U5MPcP8GK183KB6c/AWs/MTOnfMXmSxH2m6nmJTkmwO0pzdiCVuYUc9qTX1f9fMIh6Tx53iCw2HA6HCYlZ7HteeWOdiwS0fhDEdyOvbf8Zy/exu2vL6t97Iaj6JuZiN2qSKizQ0PVbER3au1yAx6ft4ZPf97FypwSuqS4eO6yEZz97LcEw+a7l5Xk5IObjyY72dXg8/fH1oJyFqzcwoOfbsZuU/zpuF4ce1gvuqTu/2efU1jB+H8uIFxjwdO7TjqEa8b3wWaxsHRrEWc9803VbPtEp415d4ync0oDv8tbZNZv3P0zTPiTGYsdfqnJSjRHYPCVmFsytnxnbpG5+I09N3bCQdMInTLJ/HzhTDMpq6WWeDMkzdjCYrJnFolo8ssDaK1xOaxVG3EqpTizTwTrtOtNmqH/cagdyyASpuTqb7HsWEri/7d35/FRVucCx39n9kwWsoeEsO+rgIgsKkhVUBG8VuuCthavS4u74kXtcm17e+ttP7W4lFYtilZQXKpUra0KqLiwKgJlVZYAARKyZ5LJLOf+cSYkQ4IEzGTekOf7+eSTMy8Tfci8wzPvc877nA9+jj771tYJxOYwiWrDYlNeKdttrsAKvzQ96vqcZ1ab2Z3mU2dKM7X5NpCX6uHiobm8tcHcc7W2oIpDfidd0yNlsjjEZAXFVX5e/3wfK3eWMHlwDpMG5JCe2LTjQygc5oNt0WWmX106hJ3F1Tz8zhayk93cfX5/uqYlYK/vOnKcLutaa4qr/DhsNrKSPWzcZ0qQheW1PL1iJ2/MGs9bGwpJ87q45LQ8spJbp8NEToqHiUO6s68anHYbE4d0O6H/dqmvjqIKP8VVtZTVBKMSGcDbGwq58ox80hPd9MlK4o1Z43nyw6/plODk5gm9j719kjPBrET1pJol+V1GmrG7Fa6u/VVmhW3BZ2aBRsFKU2bsc55ZuNTk+ZWw9jlTKlQ2U2bsOjrWyUzEmOWuzGoDIdbtLuW+V79kf1kNkwd35hfThxx5Q+qyAtRbd1F1wSMoQiTufBc99ArKw17cuoYEh2qd8lM4bHoIPj/dJKzCL8wy76qD8NHvTPnh7i2tWur6Nkqq6yjz1VFeE6BLagKZSe7m5y46iJJqP7cv+pwVOxr2GfvhuB7Mnty/6VUW8NaGQma9sA6AMb3SuWRYHg++vvHInye7Hbx3z4SGRRrfwOcPsmZ3KT99YyMlVX5e/fF4bliwmoIS0/0+K8nNm7edRc4xGmbHS3lNgD+8t41nPt5FpwQnT1wzgmv/sirqOd8blc9D04ZEXenWBkLYlcLpOE7JMFhnPiDabNHjb6um1LQsC4dg3O2mC4/W5gZ/bzOt0kp3m0VHV71gkumCS8zio5zB3z6WY+u4b8Y2YrlkdqC8hnP+bzl1oYb5hxlnduMnFw9qeAPVlDV8Gm48bm2+w2ZFXe5pZl6p8gA8e7Gp/1cegLPuhnG3tri3oGg7e0t9nPXwsqhjboeND+87t9mEVFJdx9z3trFw1R7um9yfdzYdZO3u0qjnPPX9UZw/6PjL2I8uz/XKTOTP153OvrIa6oJhhndNJSvZfeJ9HI+hojZAdW2QkNZ4XfaTbqy9v6yGcb9ZeuTxry4dwr/3l7NwVQEA3TO8LLpxDHknUbKMOV+pSRcJadHj5oQCkdK708zH1o+lzNiuWa7MWFBSE5XIAD7YVsQd5wUakllrbaQXCpp7vRwes6qqflz/ac6bAd3Hm0+PAZ8pM2b0NSuadn8Knzxq7gESlmNXCqWiWy26HbZjNmxPT3Qxe8oAfnxuHxSweldpM89pWbl2w76KqPLc18XV3L14Pc/fMJrUluxxdgJKqut49L1tPPfZbsIaRvVI408zTiezhaXFkuo6NhdWsGJ7EdNHdIn6s4f+von/mjyAFf91LoGQJsntaLVyaKtrfAXW3NVYY3ZndOm9g5bhTzWWW1+am9r009HgvBQSmt2M81sKVMMfz4RPHzO9/p44w6xwatwRob4M4vRC97PNjZnedNOp45qXzDJxYTmJbgfXjO4Wdezu8/uRmtCQTEqr69hz2MeOQ1UUV/lJcjvISfGQneLhvin9o865kd1T6Z6R2KL/d8/Mpn0rB+Ym43a0/jm8p6SaZz/dfWRT2jW7Slm4ag/BRptJ1vdOrKyNXmlY7Q8yb/lXzHh6JfM++JrCslry0xquugIhzb7yGjKS3PTMTLRuIhMCq1yZNdrHKC3ByW+vGMYDr20gENL0yPDy06mDSPbE4NOTcphuGS/NMJ0Wek+Cvt9pfp8jAHdi82NhOSkJTu65oB/Th+exdncp5/TNoktaAq7IvM7hKj8P/m0j72wyDZl7ZSay6KYxR0qQ3TO8LLt3Amt2l5Kd7KZXVtKxFzccJTvFw8zxPXjmk11oDT0yvNx5Xr/jrqhsqcNVfnYcqqK6LsSew03biq3eVUJtXQ+SPDbKfHW8s+kAf/1sN5lJbh64cCA9s7w47XYqa4M8+0nDfWK/+ccWHrt6BM9/uputByu5eGguV57RNTYfJIVoZfFPZuEw4cM78CsPb+7UTO9Wy2W9E5k4ZxK+uhBeVwxLGw43pPc0K5p02Oy9JZvwnTLSE92M7uk+srddRU2AwvIa/IEwheU1RxIZmFLg/I93cs/5/XE5bDjtdjq765g6LM88obYcaNl5mOZ1ced5/fjPs3tRFwyT6LaTldw68zEl1X7uWryeD7cVkeZ18vg1I5s8Z/LgznhdDrTWvLf5IHNe3XDkz1Z+XcKyeydEls9rGi9W3HqwkhufW8Pbt5+N3abolOBs2W7ZQlhA3M/UUG0Ftjd+RMIL05js3oTr2cmopb8k3V5L94wYlzYC1aYnYe9JMO1xWP0kbP3nNzdeFe1SuS/AX1bsZNxvljL7lfV8vqesyXO2FFZSV7+jc9ke02C5prRhfAKd0lMSnOSlJtAjM7HVEhnA4ao6PtxmGlCX+gKs3V3Kzy8ZRKrXictu49ox3bhoaGdsNkWZL8DClXuifr4mEOLLveZm50S3g++OjJ4nO7d/NgkuOxlJbklkol2J+2VIcdBDePJT5L58MSmvXU2483B2nX4/yUEPWcf/8W9HOUzHjozeZk4ss68ZH6vMKNqt8toAc9/fDsDmwkpmTx7QZIHIf4zsQpLHaT7MVOw3c6mHNsGBjeDpRHjMjzhcUYvLacemoMwXYNvBSvpmJ5GW6IpNKfwovrroVm2/f3cbM8f34O3bz8ZhUyR5HHhd5m3tctgiV2DRiTs7xXxATPY4mXPhQM7qk8X7Ww5ybv9szumX2SZ/DyFaW9yTmR2NPeQzPQIBW20pXluobe6RcidC/uiGRR75o4/aKDKGy/5FmzpY0bBnV5U/yDsbC5l75XDmvr+DytoA14/rwYRIr0QcLtNzcfKvzWaqykb4lhU8/kkxL67ewHVju5PmdTHntYby3f9eNpTLRnTBHeP5pbxUD51TPBxo9PfpkZFITrK74YbuiES3g9mT+7NiexEVtUEAzu6bSde0hgUq6Ykupg3P46JhnXG0xj1fQsRJ3O8zC/nKsC/8LiHlpPriJ0h5+QrCXc5AT3kYu7eNE0lFISy51Wx9YnfCG7PMOLVr28YhWt3Bilom/HYZtYGGVX6/mDaYKUM6g4LUBNeRxSGAKS3On2LuL/QdJjDkStb2vZNrF25nwczR3Pz8Wqr8wSNPT3TZWXrvxBbdVP1t7S+r4U/Lv+Lr4mq+Nyqfs/tmkdZMZxOAUChMcXUd2w5WkuZ1kdvJQ0YLF7KIViX3mcVY/K/MvKmErniemqDihQ3VzJyxBIfT1faJrF55Acy/wNxvFjpG01TR7qR5nbx401geeG0DBSU+pp6Wy0XDcptfoVhfZkzMhBmvEC7ahvNfD9J1tBuvy47TbotKZADVdaEmrZ9aS10wRKkvgD8QwuOyk5Pi4SdTB1IbCJOS8M0lQbvdRk6Kp02SrBDxFPcrs5ir2G++p+RFxuqbtzQp3m52gAaza3T3cTEPUbSdw1V+QmFzA3Bzba2OCNSaJtKeTlRWVVJbU8O0pzdQWF7LQ9MG886mA3z6VUOrrDG90pl37emktfJN0XXBECt3ljDrhXVU1AbJTnazYOZoBuZao41aE41us4kaC/lFxFj7KJLX+ZofH09NGfz9dlgwFQ5ugldmmg0yqw6ZP68uil6hVnnAbOOSnGsaGf/tZigraJ2/g7CEjCQ32Smeb05kYFobecy2L8lJyRT6XZT5zJX648t28MvpQ7h+XA/65yTz/bHdefSqEa2eyMCsWPzxX9cdmfM6VOnntkWfU1zlP85PxkF1kdkqKehvNK49/s8J0QriXmY8Ll8JrF8EQy8328V/sdCMk1qw1XtCKkyda8qG88bBrJXw2s1ml+BzZsNzl8KgS+HMm03DYK3Npo8zXja92pbMiv3fT7QLAzons3z2RPaV1ZCV5CYlwcmcCwdQ5Q+S5HbgidHCj9pAiMqjSpo7DlXFrKR50gI18MWLsPQXcPmzsHIeFG+F2z5vD//KiFOA9U+zUB2seAS+XAzZgyJ7i40ymzm2ZHdapUBFnrd+MZz7ALx4Naz6s/lvDPteQ+f7lFz47vyGFYyNx6JDczns5KTYm8w9xSqJ1Utw2clKclPU6EpsRNdUnHaLVa2cCTDiGti/Dl66xsw53/xhh9xDT8SH9cuMSTlww7tmC5b1C+GSxyB3WMsSWU0ZLLnNJLQbl8KuFeY+Mm+GWdzR9cymyaq1mhhbjD8Q4lBlLUWVfut9qhfHlO51sWDmGfTOMu3ThndN5dGrR5x0Z/yY0mFTqgcIB8wN52FZRCXahvWvzGpK4bN5puWUwwOrnzL9E7/pE1/9xHNCKlwy1xzrlA/XLILnLzNXauf9t9loM2dIQ5nxFFVaXcf8j3ey4JNdJLod/OTigZzTL0tujm0HHHYbg/I68dJNYwlqjctua3aD0birLzMe+jfcsgI+/SMsvk7KjKLNWH81Y+UBeHIiXDrPLMp4ZgpcsQDyRzV/dVZ5EHzFkNnPzLfVlpv+i3anuTG7YCWk94akbLPFenpvSOveOrFa1Kvr9nLP4vVRx967ewJ9spvZhVeIk+U7bN5jKV3MQqv6cUuqKKc+i9WFTz3W/8yUlAO3rjZvCEdCw7i5N4i/Cj57AlY9BZfPh2X/Y95QN39okpkr0Sy1d0TmPRqPT1FV/iB/X7+/yfGPthdJMhOty5thvo4eC9EGrD9nppTZONPpjR43x50E4+6AbmNg0VVmWf11r5ufqdc4eZ3iiQzA47AxLL9Tk+OD85oeE0KI9sr6yexEhYMNk9DBWjPn1oE7eTjsNq4b051BjW6yvXR4Hn2yZT82IcSpw/plxhNRX2asKYHb1sG7P4NXfthQZuygspI9PHfDaKr9QRw2RaLbQWoMbvAVQoh4sf4CkBNVXWw6EHTqEj1u50qr6/iqqIqPdxQzrncmfSLbjggh2gVZABJjp9aVGZjmsM2N2zGfP8hTH33NH5d/BcAj723nlgm9uG1SXxKP15ZJCCE6AGvOmdUvqT963EFV+IM8/dHOqGPzV+xq0rldCCE6Kusls5pScy/Zl4tNmfCZKbDl7SObd3Y04bAGrQmGw1HHg+EwsSgRCyFEe2S9ZKZscOYt8Pa9MHeY6SzQ4yxzj1gHUuar45Ovipn9ynoKSnxMH54X9efTTsvD65ISoxBCgBXnzDydYOA0+NdPoa4KRl5/SvVIbIlgKMySL/bzsyWbAPjHxgMsmDmaMb0yWL61iIn9szl/UPZxN2YUQoiOwnrJrKYUnr0IEtJg1A/hk8eg81AYNK3DXJ2V+up4YvmOI499dSGu+NOnfHb/JC4d3gV3jDu1CyFEe2O9ZKZscNY9ptVUQhp0HgbdxnaYRFbP3swOvf5gWBKZEEI0w3pzZp5OMPASSO1q2lMNmGrGHUi618Vd5/eLOja2V7p0uRdCiGOw3pUZgMvb/LiDsNttXDA4h/6dx/Pm+kKG5ndibO8Ma279IYQQFmDNZCbolOBiWL6LYfkda/GLEEKcDOuVGYUQQogTJMlMCCFEuyfJTAhhfVpDTXnTsRARksyEENamNZTuMjvH15Q2jH2H4x2ZsBBZACKEsLZw0DQcX7cAijZD0RZIzoNwKN6RCQuRKzMhhLXZnaYL0ORfw84PTQPy778BSdnxjkxYiCQzIYS1aQ0V++CDhyG1m0lub90rZUYRRZKZEMLa6suMaT3hxqVw/VtQXiBlRhFFxWJPrFGjRuk1a9a0+n9XCNFBBf1mO6iE1Ohx+9G02apoVS26MlNKTVFKbVVK7VBKzYl1UEIIEcXhbkhejcdCRBw3mSml7MATwIXAIOBqpdSgWAcmhBBCtFRLrsxGAzu01l9rreuAF4HpsQ1LCCGEaLmWJLMuQEGjx3sjx6IopW5SSq1RSq0pKipqrfiEEEKI42pJMmtu4rLJqhGt9ZNa61Fa61FZWVnfPjIhhBCihVqSzPYCjXfHzAf2xyYcIYQQ4sS1JJmtBvoqpXoqpVzAVcCS2IYlhBBCtNxxezNqrYNKqVuBfwJ2YL7WelPMIxNCCCFaqEWNhrXWbwNvxzgWIYQQ4qRIOyshhBDtniQzIYQQ7Z4kMyGEEO1eTBoNK6WKgN0n8aOZQHErh9NarBqbVeMC68Zm1bjAurFZNS6wbmyN4yrWWk+JZzCnupgks5OllFqjtR4V7ziaY9XYrBoXWDc2q8YF1o3NqnGBdWOzalynKikzCiGEaPckmQkhhGj3rJbMnox3AN/AqrFZNS6wbmxWjQusG5tV4wLrxmbVuE5JlpozE0IIIU6G1a7MhBBCiBMmyUwIIUS7Z5lkppSaopTaqpTaoZSaE+dY5iulDimlNjY6lq6UelcptT3yPS0OcXVVSi1TSm1WSm1SSt1hhdiUUh6l1Cql1PpIXA9FjvdUSq2MxPVSZNeFNqeUsiulPldKvWmxuHYppTYopb5QSq2JHIv7eRaJI1Up9YpSakvkfBsb79iUUv0jv6v6rwql1J3xjisS212Rc3+jUmpR5D1hifOso7BEMlNK2YEngAuBQcDVSqlBcQzpWeDoGxznAO9rrfsC70cet7UgcI/WeiAwBpgV+T3FOzY/MElrfRowHJiilBoDPAw8EomrFLihjeOqdwewudFjq8QFcK7Wenij+5Hi/VrWmwu8o7UeAJyG+f3FNTat9dbI72o4cDrgA/4W77iUUl2A24FRWushmN1FrsJa59mpT2sd9y9gLPDPRo/vB+6Pc0w9gI2NHm8FciPjXGCrBX5vbwDnWyk2wAusA87EdD9wNPcat2E8+Zh/4CYBb2J2To97XJH/9y4g86hjcX8tgRRgJ5EFYlaKrVEsFwAfWyEuoAtQAKRjdiJ5E5hslfOso3xZ4sqMhpOh3t7IMSvJ0VoXAkS+Z8czGKVUD2AEsBILxBYp5X0BHALeBb4CyrTWwchT4vWa/gG4DwhHHmdYJC4ADfxLKbVWKXVT5FjcX0ugF1AEPBMpzz6tlEq0SGz1rgIWRcZxjUtrvQ/4HbAHKATKgbVY5zzrEKySzFQzx+SegWNQSiUBrwJ3aq0r4h0PgNY6pE35Jx8YDQxs7mltGZNSaipwSGu9tvHhZp4ar3NtvNZ6JKa8PkspdU6c4jiaAxgJzNNajwCqiV+5s4nI3NM04OV4xwIQmaObDvQE8oBEzGt6NPk3LYasksz2Al0bPc4H9scplmM5qJTKBYh8PxSPIJRSTkwie0Fr/ZqVYgPQWpcByzFzeqlKqfoNYOPxmo4HpimldgEvYkqNf7BAXABorfdHvh/CzP2Mxhqv5V5gr9Z6ZeTxK5jkZoXYwCSKdVrrg5HH8Y7rPGCn1rpIax0AXgPGYZHzrKOwSjJbDfSNrP5xYUoIS+Ic09GWAD+IjH+Ama9qU0opBfwF2Ky1/r1VYlNKZSmlUiPjBMybezOwDLg8XnFpre/XWudrrXtgzqmlWusZ8Y4LQCmVqJRKrh9j5oA2YoHzTGt9AChQSvWPHPoO8G8rxBZxNQ0lRoh/XHuAMUopb+Q9Wv/7ivt51qHEe9Ku/gu4CNiGmWt5MM6xLMLUvgOYT6k3YOZa3ge2R76nxyGuszClii+BLyJfF8U7NmAY8Hkkro3AzyLHewGrgB2YkpA7jq/pROBNq8QViWF95GtT/Tkf79eyUXzDgTWR1/R1IM0KsWEWGB0GOjU6ZoW4HgK2RM7/5wG3Fc6zjvQl7ayEEEK0e1YpMwohhBAnTZKZEEKIdk+SmRBCiHZPkpkQQoh2T5KZEEKIdk+SmRBCiHZPkpkQQoh27/8BnADaJ52phBQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 442.5x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'const':loo_const.pareto_k, 'everyday':loo_every.pareto_k})\n",
    "sns.relplot(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const       27\n",
       "everyday    46\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loo(sm):\n",
    "    log_likelihood = 0\n",
    "    for i in range(C0.shape[0]-1):\n",
    "        print('\\rNo, %d' % i, end='')\n",
    "        data_LOO = {'T': C0.shape[0], 'T0': i+1, 'P': P, 'C0': C0, 'R0': R0, 'D0':D0}\n",
    "        fit_loo = sm_const.sampling(data=data_LOO, iter=2000, init='random')\n",
    "        data_loo = az.from_pystan(fit_loo, log_likelihood='log_lik')\n",
    "        log_likelihood += data_loo.sample_stats['log_likelihood'].sel(log_likelihood_dim_0=i).mean()\n",
    "        \n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:1953 of 4000 iterations saturated the maximum tree depth of 10 (48.8 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "No, 2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:502 of 4000 iterations saturated the maximum tree depth of 10 (12.6 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, 4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:2503 of 4000 iterations saturated the maximum tree depth of 10 (62.6 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "No, 5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:1564 of 4000 iterations saturated the maximum tree depth of 10 (39.1 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "No, 6"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:270 of 4000 iterations saturated the maximum tree depth of 10 (6.75 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "No, 7"
     ]
    }
   ],
   "source": [
    "loo(sm_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo(sm_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(data, upto):\n",
    "    index=pd.date_range(start=epoch, end=upto)\n",
    "    b = pd.DataFrame(data_every.posterior['b'].stack(sample=('chain', 'draw')).values, index=index)\n",
    "    q = pd.DataFrame(data_every.posterior['q'].stack(sample=('chain', 'draw')).values, index=index)\n",
    "    NI = pd.DataFrame(data_every.posterior['NI'].stack(sample=('chain', 'draw')).values, index=index)\n",
    "    a = pd.DataFrame(data_every.posterior['a'].stack(sample=('chain', 'draw')).values)\n",
    "    d = pd.DataFrame(data_every.posterior['d'].stack(sample=('chain', 'draw')).values)\n",
    "    p = pd.DataFrame(data_every.posterior['d'].stack(sample=('chain', 'draw')).values)\n",
    "    C = NI.cumsum()\n",
    "    NI0 = q*NI\n",
    "    C0 = NI0.cumsum()\n",
    "    return a, d, p, b, q, NI, NI0, C, C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_e, d_e, p_e, b_e, q_e, NI_e, NI0_e, C_e, C0_e = extract(data_every, upto=pd.to_datetime('2020-04-18'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(simulated, real=None, upto=pd.to_datetime('2020-04-18')):\n",
    "    graph=pd.DataFrame(index=pd.date_range(start=epoch, end=upto))\n",
    "    simulated = simulated.dropna(axis=1)\n",
    "    median = simulated.median(axis=1)\n",
    "    upper = simulated.quantile(q=0.75, axis=1)\n",
    "    lower = simulated.quantile(q=0.25, axis=1)\n",
    "    if not real is None:\n",
    "        graph['Real'] = real\n",
    "    graph['Median'] = median\n",
    "    graph['Upper'] = upper\n",
    "    graph['Lower'] = lower\n",
    "    sns.relplot(kind=\"line\", data=graph, aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(C0_e, real=confirmed[country])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(q_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(b_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw(C_e, real=confirmed[country])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COVID-19",
   "language": "python",
   "name": "covid-19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
